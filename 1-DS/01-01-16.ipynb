{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c75ae2",
   "metadata": {},
   "source": [
    "# Introduction to Probability Concepts\n",
    "\n",
    "This notebook introduces fundamental probability concepts essential for data science applications. We'll explore theoretical concepts and implement practical examples using Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53216c9",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Let's start by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606c6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93de71ee",
   "metadata": {},
   "source": [
    "## 1. Basic Probability Concepts\n",
    "\n",
    "Probability theory provides the mathematical foundation for statistics and many machine learning algorithms. Let's start with the basics:\n",
    "\n",
    "- **Sample Space (S)**: The set of all possible outcomes of an experiment.\n",
    "- **Event (E)**: A subset of the sample space (a collection of possible outcomes).\n",
    "- **Probability (P)**: A measure of the likelihood that an event will occur, with values between 0 and 1.\n",
    "\n",
    "### Example: Coin Toss and Dice Roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sample spaces\n",
    "coin_sample_space = ['H', 'T']\n",
    "dice_sample_space = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Calculate simple probabilities\n",
    "p_heads = 1 / len(coin_sample_space)\n",
    "p_six = 1 / len(dice_sample_space)\n",
    "\n",
    "print(f\"Probability of getting heads in a fair coin toss: {p_heads}\")\n",
    "print(f\"Probability of rolling a 6 on a fair die: {p_six}\")\n",
    "\n",
    "# Simulate coin tosses\n",
    "num_tosses = 10000\n",
    "coin_tosses = np.random.choice(coin_sample_space, size=num_tosses)\n",
    "heads_count = np.sum(coin_tosses == 'H')\n",
    "empirical_p_heads = heads_count / num_tosses\n",
    "\n",
    "print(f\"\\nAfter {num_tosses} tosses, empirical probability of heads: {empirical_p_heads:.4f}\")\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(['Heads', 'Tails'], [np.sum(coin_tosses == 'H'), np.sum(coin_tosses == 'T')])\n",
    "plt.title('Coin Toss Simulation')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "dice_rolls = np.random.choice(dice_sample_space, size=num_tosses)\n",
    "plt.hist(dice_rolls, bins=np.arange(0.5, 7.5, 1), edgecolor='black', alpha=0.7)\n",
    "plt.title('Dice Roll Simulation')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(range(1, 7))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0e1f56",
   "metadata": {},
   "source": [
    "### Example: Cards Probability\n",
    "\n",
    "Let's calculate the probability of drawing specific cards from a standard deck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6152707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cards in a standard deck\n",
    "suits = ['Hearts', 'Diamonds', 'Clubs', 'Spades']\n",
    "ranks = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'Jack', 'Queen', 'King', 'Ace']\n",
    "\n",
    "# Create a deck of cards\n",
    "deck = [(rank, suit) for rank in ranks for suit in suits]\n",
    "\n",
    "# Display deck size\n",
    "print(f\"Total cards in the deck: {len(deck)}\")\n",
    "\n",
    "# Calculate probabilities\n",
    "p_ace = len([card for card in deck if card[0] == 'Ace']) / len(deck)\n",
    "p_heart = len([card for card in deck if card[1] == 'Hearts']) / len(deck)\n",
    "p_face_card = len([card for card in deck if card[0] in ['Jack', 'Queen', 'King']]) / len(deck)\n",
    "\n",
    "print(f\"Probability of drawing an Ace: {p_ace:.4f}\")\n",
    "print(f\"Probability of drawing a Heart: {p_heart:.4f}\")\n",
    "print(f\"Probability of drawing a face card (Jack, Queen, or King): {p_face_card:.4f}\")\n",
    "\n",
    "# Function to calculate probability of a given condition\n",
    "def card_probability(condition):\n",
    "    matching_cards = [card for card in deck if condition(card)]\n",
    "    return len(matching_cards) / len(deck)\n",
    "\n",
    "# Calculate probability of drawing a red card (Hearts or Diamonds)\n",
    "p_red = card_probability(lambda card: card[1] in ['Hearts', 'Diamonds'])\n",
    "print(f\"Probability of drawing a red card: {p_red:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b49930",
   "metadata": {},
   "source": [
    "## 2. Probability Rules and Axioms\n",
    "\n",
    "Probability follows specific mathematical rules that allow us to calculate complex probabilities:\n",
    "\n",
    "1. **Non-negativity**: P(E) ≥ 0 for any event E\n",
    "2. **Total probability**: P(S) = 1 for the sample space S\n",
    "3. **Addition Rule**: P(A or B) = P(A) + P(B) - P(A and B)\n",
    "4. **Multiplication Rule**: P(A and B) = P(A) × P(B|A)\n",
    "\n",
    "Let's implement these rules in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a916a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to demonstrate the addition rule\n",
    "def addition_rule_demo(n=1000):\n",
    "    \"\"\"Demonstrate the addition rule with a simulation.\"\"\"\n",
    "    # Simulate drawing cards\n",
    "    draws = np.random.choice(range(len(deck)), size=n)\n",
    "    cards_drawn = [deck[i] for i in draws]\n",
    "    \n",
    "    # Define events\n",
    "    event_A = [card for card in cards_drawn if card[0] == 'Ace']  # Drawing an Ace\n",
    "    event_B = [card for card in cards_drawn if card[1] == 'Hearts']  # Drawing a Heart\n",
    "    event_A_and_B = [card for card in cards_drawn if card[0] == 'Ace' and card[1] == 'Hearts']  # Drawing Ace of Hearts\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    p_A = len(event_A) / n\n",
    "    p_B = len(event_B) / n\n",
    "    p_A_and_B = len(event_A_and_B) / n\n",
    "    p_A_or_B = p_A + p_B - p_A_and_B\n",
    "    \n",
    "    # Theoretical probabilities\n",
    "    p_A_theoretical = 4/52  # 4 Aces in 52 cards\n",
    "    p_B_theoretical = 13/52  # 13 Hearts in 52 cards\n",
    "    p_A_and_B_theoretical = 1/52  # 1 Ace of Hearts in 52 cards\n",
    "    p_A_or_B_theoretical = p_A_theoretical + p_B_theoretical - p_A_and_B_theoretical\n",
    "    \n",
    "    print(\"=== Addition Rule Demo ===\")\n",
    "    print(f\"Empirical P(Ace) = {p_A:.4f}, Theoretical = {p_A_theoretical:.4f}\")\n",
    "    print(f\"Empirical P(Heart) = {p_B:.4f}, Theoretical = {p_B_theoretical:.4f}\")\n",
    "    print(f\"Empirical P(Ace and Heart) = {p_A_and_B:.4f}, Theoretical = {p_A_and_B_theoretical:.4f}\")\n",
    "    print(f\"Empirical P(Ace or Heart) = {p_A_or_B:.4f}, Theoretical = {p_A_or_B_theoretical:.4f}\")\n",
    "    print(f\"Verification: P(A) + P(B) - P(A and B) = {p_A + p_B - p_A_and_B:.4f}\")\n",
    "    \n",
    "    # Visualize with a Venn diagram\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    from matplotlib_venn import venn2\n",
    "    v = venn2(subsets=(len(event_A) - len(event_A_and_B), \n",
    "                       len(event_B) - len(event_A_and_B), \n",
    "                       len(event_A_and_B)), \n",
    "             set_labels=('Ace', 'Heart'))\n",
    "    plt.title('Venn Diagram: Drawing an Ace or a Heart')\n",
    "    plt.show()\n",
    "\n",
    "addition_rule_demo(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da596c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate mutually exclusive events\n",
    "def mutually_exclusive_demo(n=1000):\n",
    "    \"\"\"Demonstrate mutually exclusive events.\"\"\"\n",
    "    # Simulate dice rolls\n",
    "    dice_rolls = np.random.randint(1, 7, size=n)\n",
    "    \n",
    "    # Define events\n",
    "    event_A = dice_rolls == 1  # Rolling a 1\n",
    "    event_B = dice_rolls == 2  # Rolling a 2\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    p_A = np.mean(event_A)\n",
    "    p_B = np.mean(event_B)\n",
    "    p_A_and_B = np.mean(event_A & event_B)  # This should be 0\n",
    "    p_A_or_B = np.mean(event_A | event_B)\n",
    "    \n",
    "    print(\"=== Mutually Exclusive Events Demo ===\")\n",
    "    print(f\"P(Rolling 1) = {p_A:.4f}\")\n",
    "    print(f\"P(Rolling 2) = {p_B:.4f}\")\n",
    "    print(f\"P(Rolling 1 AND 2) = {p_A_and_B:.4f}\")  # Should be 0\n",
    "    print(f\"P(Rolling 1 OR 2) = {p_A_or_B:.4f}\")\n",
    "    print(f\"P(1) + P(2) = {p_A + p_B:.4f}\")  # For mutually exclusive events, P(A or B) = P(A) + P(B)\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    labels = ['1', '2', '3', '4', '5', '6']\n",
    "    values, counts = np.unique(dice_rolls, return_counts=True)\n",
    "    plt.bar(labels, [counts[values == i][0] if i in values else 0 for i in range(1, 7)], alpha=0.7)\n",
    "    plt.axhline(y=n/6, color='r', linestyle='--', label='Expected Value')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Dice Value')\n",
    "    plt.title('Distribution of Dice Rolls')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "mutually_exclusive_demo(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075905c",
   "metadata": {},
   "source": [
    "## 3. Conditional Probability\n",
    "\n",
    "Conditional probability represents the probability of an event occurring given that another event has already occurred.\n",
    "\n",
    "The formula for conditional probability is:\n",
    "\n",
    "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "Where:\n",
    "- $P(A|B)$ is the probability of event A given that event B has occurred\n",
    "- $P(A \\cap B)$ is the probability of both events A and B occurring\n",
    "- $P(B)$ is the probability of event B occurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f922839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to demonstrate conditional probability\n",
    "def conditional_probability_demo():\n",
    "    \"\"\"Demonstrate conditional probability with cards example.\"\"\"\n",
    "    \n",
    "    # Define some events\n",
    "    def is_red(card):\n",
    "        return card[1] in ['Hearts', 'Diamonds']\n",
    "    \n",
    "    def is_face_card(card):\n",
    "        return card[0] in ['Jack', 'Queen', 'King']\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    red_cards = [card for card in deck if is_red(card)]\n",
    "    face_cards = [card for card in deck if is_face_card(card)]\n",
    "    red_face_cards = [card for card in deck if is_red(card) and is_face_card(card)]\n",
    "    \n",
    "    p_red = len(red_cards) / len(deck)\n",
    "    p_face = len(face_cards) / len(deck)\n",
    "    p_red_and_face = len(red_face_cards) / len(deck)\n",
    "    \n",
    "    # Conditional probabilities\n",
    "    p_face_given_red = len(red_face_cards) / len(red_cards)  # P(Face | Red)\n",
    "    p_red_given_face = len(red_face_cards) / len(face_cards)  # P(Red | Face)\n",
    "    \n",
    "    # Calculate from formula as verification\n",
    "    p_face_given_red_formula = p_red_and_face / p_red\n",
    "    \n",
    "    print(\"=== Conditional Probability Demo ===\")\n",
    "    print(f\"P(Red) = {p_red:.4f}\")\n",
    "    print(f\"P(Face) = {p_face:.4f}\")\n",
    "    print(f\"P(Red and Face) = {p_red_and_face:.4f}\")\n",
    "    print(f\"P(Face | Red) = {p_face_given_red:.4f}   Formula: {p_face_given_red_formula:.4f}\")\n",
    "    print(f\"P(Red | Face) = {p_red_given_face:.4f}\")\n",
    "    \n",
    "    # Visualize card distribution\n",
    "    card_categories = {\n",
    "        \"Red Face Cards\": len(red_face_cards),\n",
    "        \"Black Face Cards\": len(face_cards) - len(red_face_cards),\n",
    "        \"Red Non-Face Cards\": len(red_cards) - len(red_face_cards),\n",
    "        \"Black Non-Face Cards\": len(deck) - len(red_cards) - len(face_cards) + len(red_face_cards)\n",
    "    }\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(card_categories.keys(), card_categories.values(), color=['red', 'darkgray', 'lightcoral', 'lightgray'])\n",
    "    plt.ylabel('Number of Cards')\n",
    "    plt.title('Distribution of Cards in a Standard Deck')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "conditional_probability_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7b594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate independence of events\n",
    "def independence_demo(n=10000):\n",
    "    \"\"\"Demo independence of events using dice rolls.\"\"\"\n",
    "    \n",
    "    # Simulate rolling two dice\n",
    "    dice1 = np.random.randint(1, 7, size=n)\n",
    "    dice2 = np.random.randint(1, 7, size=n)\n",
    "    \n",
    "    # Event A: First die shows 6\n",
    "    event_A = dice1 == 6\n",
    "    p_A = np.mean(event_A)\n",
    "    \n",
    "    # Event B: Second die shows 3\n",
    "    event_B = dice2 == 3\n",
    "    p_B = np.mean(event_B)\n",
    "    \n",
    "    # Joint probability\n",
    "    event_A_and_B = event_A & event_B\n",
    "    p_A_and_B = np.mean(event_A_and_B)\n",
    "    \n",
    "    # Conditional probabilities\n",
    "    p_A_given_B = np.mean(event_A[event_B]) if np.any(event_B) else 0\n",
    "    p_B_given_A = np.mean(event_B[event_A]) if np.any(event_A) else 0\n",
    "    \n",
    "    print(\"=== Independence of Events Demo ===\")\n",
    "    print(f\"P(Die1 = 6) = {p_A:.4f}\")\n",
    "    print(f\"P(Die2 = 3) = {p_B:.4f}\")\n",
    "    print(f\"P(Die1 = 6 and Die2 = 3) = {p_A_and_B:.4f}\")\n",
    "    print(f\"P(Die1 = 6) × P(Die2 = 3) = {p_A * p_B:.4f}\")\n",
    "    print(f\"P(Die1 = 6 | Die2 = 3) = {p_A_given_B:.4f}\")\n",
    "    print(f\"P(Die2 = 3 | Die1 = 6) = {p_B_given_A:.4f}\")\n",
    "    \n",
    "    # Two events are independent if P(A and B) = P(A) × P(B)\n",
    "    print(f\"\\nAre the events independent? {abs(p_A_and_B - (p_A * p_B)) < 0.01}\")\n",
    "    \n",
    "    # Visualize joint distribution\n",
    "    contingency = pd.crosstab(dice1, dice2)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(contingency, annot=True, cmap=\"YlGnBu\", fmt='d', cbar=True)\n",
    "    plt.title('Joint Distribution of Two Dice Rolls')\n",
    "    plt.xlabel('Second Die')\n",
    "    plt.ylabel('First Die')\n",
    "    plt.show()\n",
    "\n",
    "independence_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb5b991",
   "metadata": {},
   "source": [
    "## 4. Probability Distributions\n",
    "\n",
    "Probability distributions describe the likelihood of all possible outcomes of a random variable. They are crucial for statistical analysis and modeling.\n",
    "\n",
    "### Discrete Probability Distributions\n",
    "\n",
    "1. **Bernoulli Distribution**: Models a single binary outcome (success/failure)\n",
    "2. **Binomial Distribution**: Models the number of successes in n independent Bernoulli trials\n",
    "3. **Poisson Distribution**: Models the number of events occurring in a fixed time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43af93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli distribution\n",
    "p_success = 0.4  # probability of success\n",
    "bernoulli = stats.bernoulli(p_success)\n",
    "\n",
    "# Sample 1000 values from bernoulli distribution\n",
    "bernoulli_samples = bernoulli.rvs(size=1000)\n",
    "bernoulli_values, bernoulli_counts = np.unique(bernoulli_samples, return_counts=True)\n",
    "\n",
    "# Calculate and print mean and variance\n",
    "print(\"=== Bernoulli Distribution ===\")\n",
    "print(f\"p = {p_success}\")\n",
    "print(f\"Theoretical Mean: {p_success}\")\n",
    "print(f\"Theoretical Variance: {p_success * (1 - p_success)}\")\n",
    "print(f\"Empirical Mean: {np.mean(bernoulli_samples)}\")\n",
    "print(f\"Empirical Variance: {np.var(bernoulli_samples)}\")\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "# Plot Bernoulli PMF\n",
    "plt.subplot(2, 2, 1)\n",
    "x = np.array([0, 1])\n",
    "plt.bar(x, [1-p_success, p_success], alpha=0.7, width=0.4)\n",
    "plt.title('Bernoulli PMF (p=0.4)')\n",
    "plt.xticks([0, 1])\n",
    "plt.xlabel('Outcome')\n",
    "plt.ylabel('Probability')\n",
    "\n",
    "# Binomial distribution parameters\n",
    "n, p = 20, 0.3  # number of trials, probability of success\n",
    "binomial = stats.binom(n, p)\n",
    "\n",
    "# Plot Binomial PMF\n",
    "plt.subplot(2, 2, 2)\n",
    "x = np.arange(0, n+1)\n",
    "plt.bar(x, binomial.pmf(x), alpha=0.7)\n",
    "plt.title(f'Binomial PMF (n={n}, p={p})')\n",
    "plt.xlabel('Number of Successes')\n",
    "plt.ylabel('Probability')\n",
    "\n",
    "# Plot Binomial simulation\n",
    "plt.subplot(2, 2, 4)\n",
    "binomial_samples = binomial.rvs(size=1000)\n",
    "plt.hist(binomial_samples, bins=n+1, alpha=0.7, density=True, edgecolor='black')\n",
    "plt.title(f'Binomial Simulation (n={n}, p={p})')\n",
    "plt.xlabel('Number of Successes')\n",
    "plt.ylabel('Relative Frequency')\n",
    "\n",
    "# Poisson distribution parameter\n",
    "lam = 3  # average number of events per interval\n",
    "poisson = stats.poisson(lam)\n",
    "\n",
    "# Plot Poisson PMF\n",
    "plt.subplot(2, 2, 3)\n",
    "x = np.arange(0, 15)\n",
    "plt.bar(x, poisson.pmf(x), alpha=0.7)\n",
    "plt.title(f'Poisson PMF (λ={lam})')\n",
    "plt.xlabel('Number of Events')\n",
    "plt.ylabel('Probability')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics for binomial and poisson\n",
    "print(\"\\n=== Binomial Distribution ===\")\n",
    "print(f\"n = {n}, p = {p}\")\n",
    "print(f\"Theoretical Mean: {n*p}\")\n",
    "print(f\"Theoretical Variance: {n*p*(1-p)}\")\n",
    "print(f\"Empirical Mean: {np.mean(binomial_samples)}\")\n",
    "print(f\"Empirical Variance: {np.var(binomial_samples)}\")\n",
    "\n",
    "poisson_samples = poisson.rvs(size=1000)\n",
    "print(\"\\n=== Poisson Distribution ===\")\n",
    "print(f\"λ = {lam}\")\n",
    "print(f\"Theoretical Mean: {lam}\")\n",
    "print(f\"Theoretical Variance: {lam}\")\n",
    "print(f\"Empirical Mean: {np.mean(poisson_samples)}\")\n",
    "print(f\"Empirical Variance: {np.var(poisson_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7c942d",
   "metadata": {},
   "source": [
    "### Continuous Probability Distributions\n",
    "\n",
    "1. **Uniform Distribution**: All values in a range have equal probability\n",
    "2. **Normal (Gaussian) Distribution**: The bell-shaped curve that appears in many natural phenomena\n",
    "3. **Exponential Distribution**: Models the time between events in a Poisson process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ce2962",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Uniform distribution parameters\n",
    "a, b = 2, 8  # lower and upper bounds\n",
    "uniform = stats.uniform(a, b-a)\n",
    "\n",
    "# Plot uniform PDF\n",
    "plt.subplot(2, 2, 1)\n",
    "x = np.linspace(a-1, b+1, 1000)\n",
    "plt.plot(x, uniform.pdf(x), 'r-', lw=2)\n",
    "plt.fill_between(x, uniform.pdf(x), where=(x >= a) & (x <= b), alpha=0.3)\n",
    "plt.title(f'Uniform Distribution PDF [a={a}, b={b}]')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.ylim(0, 0.3)\n",
    "\n",
    "# Normal distribution parameters\n",
    "mu, sigma = 0, 1  # mean and standard deviation\n",
    "normal = stats.norm(mu, sigma)\n",
    "\n",
    "# Plot normal PDF\n",
    "plt.subplot(2, 2, 2)\n",
    "x = np.linspace(mu - 4*sigma, mu + 4*sigma, 1000)\n",
    "plt.plot(x, normal.pdf(x), 'b-', lw=2)\n",
    "plt.fill_between(x, normal.pdf(x), alpha=0.3)\n",
    "plt.title(f'Normal Distribution PDF [μ={mu}, σ={sigma}]')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "\n",
    "# Exponential distribution parameter\n",
    "lam = 0.5  # rate parameter\n",
    "exponential = stats.expon(scale=1/lam)\n",
    "\n",
    "# Plot exponential PDF\n",
    "plt.subplot(2, 2, 3)\n",
    "x = np.linspace(0, 10, 1000)\n",
    "plt.plot(x, exponential.pdf(x), 'g-', lw=2)\n",
    "plt.fill_between(x, exponential.pdf(x), alpha=0.3)\n",
    "plt.title(f'Exponential Distribution PDF [λ={lam}]')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "\n",
    "# Compare different normal distributions\n",
    "plt.subplot(2, 2, 4)\n",
    "params = [(0, 1), (0, 2), (2, 1), (-1, 0.5)]\n",
    "colors = ['b', 'r', 'g', 'm']\n",
    "labels = [f'μ={mu}, σ={sigma}' for mu, sigma in params]\n",
    "\n",
    "for i, (mu, sigma) in enumerate(params):\n",
    "    x = np.linspace(-6, 6, 1000)\n",
    "    y = stats.norm.pdf(x, mu, sigma)\n",
    "    plt.plot(x, y, color=colors[i], lw=2, label=labels[i])\n",
    "\n",
    "plt.title('Comparing Normal Distributions')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate samples and compare to theoretical values\n",
    "print(\"=== Continuous Distributions: Theory vs. Simulation ===\")\n",
    "\n",
    "# Uniform\n",
    "uniform_samples = uniform.rvs(size=10000)\n",
    "print(\"\\nUniform Distribution:\")\n",
    "print(f\"Theoretical Mean: {(a+b)/2}\")\n",
    "print(f\"Theoretical Variance: {(b-a)**2/12}\")\n",
    "print(f\"Empirical Mean: {np.mean(uniform_samples):.4f}\")\n",
    "print(f\"Empirical Variance: {np.var(uniform_samples):.4f}\")\n",
    "\n",
    "# Normal\n",
    "normal_samples = normal.rvs(size=10000)\n",
    "print(\"\\nNormal Distribution:\")\n",
    "print(f\"Theoretical Mean: {mu}\")\n",
    "print(f\"Theoretical Variance: {sigma**2}\")\n",
    "print(f\"Empirical Mean: {np.mean(normal_samples):.4f}\")\n",
    "print(f\"Empirical Variance: {np.var(normal_samples):.4f}\")\n",
    "\n",
    "# Exponential\n",
    "exponential_samples = exponential.rvs(size=10000)\n",
    "print(\"\\nExponential Distribution:\")\n",
    "print(f\"Theoretical Mean: {1/lam}\")\n",
    "print(f\"Theoretical Variance: {1/lam**2}\")\n",
    "print(f\"Empirical Mean: {np.mean(exponential_samples):.4f}\")\n",
    "print(f\"Empirical Variance: {np.var(exponential_samples):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddb729f",
   "metadata": {},
   "source": [
    "## 5. Random Variables\n",
    "\n",
    "A random variable is a variable whose possible values are numerical outcomes of a random phenomenon. Random variables can be:\n",
    "\n",
    "1. **Discrete**: Can take on only distinct, separate values (e.g., number of heads in coin flips)\n",
    "2. **Continuous**: Can take on any value within a continuous range (e.g., height, weight, time)\n",
    "\n",
    "Let's explore random variables further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9471b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the Central Limit Theorem\n",
    "def central_limit_theorem_demo(distribution='exponential', n_samples=1000, sample_sizes=[1, 2, 5, 30]):\n",
    "    \"\"\"\n",
    "    Demonstrate the Central Limit Theorem by showing how the distribution of\n",
    "    sample means approaches a normal distribution regardless of the original distribution.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Choose distribution\n",
    "    if distribution == 'uniform':\n",
    "        # Uniform distribution from 0 to 1\n",
    "        get_sample = lambda size: np.random.uniform(0, 1, size)\n",
    "        dist_name = \"Uniform(0, 1)\"\n",
    "        theoretical_mean = 0.5\n",
    "        theoretical_std = 1/np.sqrt(12)\n",
    "    elif distribution == 'exponential':\n",
    "        # Exponential distribution with lambda=1\n",
    "        get_sample = lambda size: np.random.exponential(1, size)\n",
    "        dist_name = \"Exponential(λ=1)\"\n",
    "        theoretical_mean = 1\n",
    "        theoretical_std = 1\n",
    "    elif distribution == 'binomial':\n",
    "        # Binomial distribution with n=10, p=0.3\n",
    "        get_sample = lambda size: np.random.binomial(10, 0.3, size)\n",
    "        dist_name = \"Binomial(n=10, p=0.3)\"\n",
    "        theoretical_mean = 10 * 0.3\n",
    "        theoretical_std = np.sqrt(10 * 0.3 * 0.7)\n",
    "    else:\n",
    "        raise ValueError(\"Distribution must be 'uniform', 'exponential', or 'binomial'\")\n",
    "    \n",
    "    # First, plot the original distribution\n",
    "    plt.subplot(len(sample_sizes) + 1, 1, 1)\n",
    "    original_samples = get_sample(n_samples)\n",
    "    plt.hist(original_samples, bins=30, alpha=0.7, density=True)\n",
    "    plt.title(f'Original Distribution: {dist_name}')\n",
    "    plt.ylabel('Density')\n",
    "    \n",
    "    # Then plot the distribution of sample means for different sample sizes\n",
    "    for i, sample_size in enumerate(sample_sizes):\n",
    "        # Generate many samples of size sample_size and calculate their means\n",
    "        sample_means = [np.mean(get_sample(sample_size)) for _ in range(n_samples)]\n",
    "        \n",
    "        plt.subplot(len(sample_sizes) + 1, 1, i + 2)\n",
    "        plt.hist(sample_means, bins=30, alpha=0.7, density=True)\n",
    "        \n",
    "        # Overlay the theoretical normal distribution\n",
    "        x = np.linspace(min(sample_means), max(sample_means), 100)\n",
    "        expected_std = theoretical_std / np.sqrt(sample_size)\n",
    "        plt.plot(x, stats.norm.pdf(x, theoretical_mean, expected_std), 'r-', lw=2)\n",
    "        \n",
    "        plt.title(f'Distribution of Sample Means (n={sample_size})')\n",
    "        plt.ylabel('Density')\n",
    "        \n",
    "        # Print statistics\n",
    "        empirical_mean = np.mean(sample_means)\n",
    "        empirical_std = np.std(sample_means)\n",
    "        expected_std = theoretical_std / np.sqrt(sample_size)\n",
    "        print(f\"Sample size {sample_size}:\")\n",
    "        print(f\"  Empirical mean: {empirical_mean:.4f}, Expected mean: {theoretical_mean:.4f}\")\n",
    "        print(f\"  Empirical std: {empirical_std:.4f}, Expected std: {expected_std:.4f}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Demonstrate CLT with different distributions\n",
    "print(\"=== Central Limit Theorem Demonstration ===\")\n",
    "central_limit_theorem_demo(distribution='exponential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f85ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Monte Carlo estimation of pi\n",
    "def estimate_pi_monte_carlo(n_samples=10000, show_progress=True):\n",
    "    \"\"\"\n",
    "    Estimate the value of π using Monte Carlo simulation.\n",
    "    We'll use the fact that the area of a circle with radius r is πr²,\n",
    "    and the area of a square with side length 2r is (2r)² = 4r².\n",
    "    So the ratio of the circle area to the square area is π/4.\n",
    "    \"\"\"\n",
    "    # Generate random points in the [0,1] × [0,1] square\n",
    "    points = np.random.random((n_samples, 2))\n",
    "    \n",
    "    # Count points inside the unit circle (centered at (0,0) with radius 1)\n",
    "    # We'll use the quarter circle in the first quadrant\n",
    "    inside_circle = np.sum(np.sum(points**2, axis=1) <= 1)\n",
    "    \n",
    "    # Ratio of points inside circle to total points approximates π/4\n",
    "    pi_estimate = 4 * inside_circle / n_samples\n",
    "    \n",
    "    if show_progress:\n",
    "        # Visualization of convergence\n",
    "        sample_sizes = np.logspace(1, np.log10(n_samples), 100).astype(int)\n",
    "        estimates = []\n",
    "        \n",
    "        for size in sample_sizes:\n",
    "            points_subset = points[:size]\n",
    "            inside_subset = np.sum(np.sum(points_subset**2, axis=1) <= 1)\n",
    "            estimates.append(4 * inside_subset / size)\n",
    "        \n",
    "        plt.figure(figsize=(14, 5))\n",
    "        \n",
    "        # Plot the points\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(points[:5000, 0], points[:5000, 1], c=np.sum(points[:5000]**2, axis=1) <= 1, \n",
    "                   cmap='coolwarm', s=2, alpha=0.7)\n",
    "        \n",
    "        # Draw the quarter circle\n",
    "        theta = np.linspace(0, np.pi/2, 100)\n",
    "        x = np.cos(theta)\n",
    "        y = np.sin(theta)\n",
    "        plt.plot(x, y, 'r-', lw=2)\n",
    "        \n",
    "        plt.title(f'Monte Carlo Estimation of π\\n{inside_circle} of {n_samples} points inside quarter circle')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.axis('equal')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Plot convergence\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.semilogx(sample_sizes, estimates, 'b-', alpha=0.7)\n",
    "        plt.axhline(y=np.pi, color='r', linestyle='--', label=f'π = {np.pi:.8f}')\n",
    "        plt.axhline(y=pi_estimate, color='g', linestyle='--', \n",
    "                  label=f'Estimate = {pi_estimate:.8f}')\n",
    "        plt.title('Convergence of π Estimate')\n",
    "        plt.xlabel('Number of Samples')\n",
    "        plt.ylabel('π Estimate')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return pi_estimate, inside_circle, n_samples\n",
    "\n",
    "# Run pi estimation\n",
    "print(\"=== Monte Carlo Estimation of π ===\")\n",
    "pi_estimate, inside, total = estimate_pi_monte_carlo(n_samples=50000)\n",
    "print(f\"Estimated π: {pi_estimate:.8f}\")\n",
    "print(f\"Actual π: {np.pi:.8f}\")\n",
    "print(f\"Absolute Error: {abs(pi_estimate - np.pi):.8f}\")\n",
    "print(f\"Relative Error: {abs(pi_estimate - np.pi) / np.pi * 100:.6f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f36c445",
   "metadata": {},
   "source": [
    "## 6. Expected Value and Variance\n",
    "\n",
    "The **expected value** (or mean) of a random variable is the long-run average value of repetitions of the experiment. The **variance** measures how far a set of values are spread out from their expected value.\n",
    "\n",
    "For a discrete random variable X with probability mass function P(X=x):\n",
    "\n",
    "$$E[X] = \\sum_{x} x \\cdot P(X=x)$$\n",
    "\n",
    "$$Var(X) = E[(X-E[X])^2] = \\sum_{x} (x-E[X])^2 \\cdot P(X=x)$$\n",
    "\n",
    "For a continuous random variable with probability density function f(x):\n",
    "\n",
    "$$E[X] = \\int_{-\\infty}^{\\infty} x \\cdot f(x) \\, dx$$\n",
    "\n",
    "$$Var(X) = E[(X-E[X])^2] = \\int_{-\\infty}^{\\infty} (x-E[X])^2 \\cdot f(x) \\, dx$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b5893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate expected value and variance for a discrete random variable\n",
    "def discrete_expectation_variance(values, probabilities):\n",
    "    \"\"\"\n",
    "    Calculate the expected value and variance for a discrete random variable.\n",
    "    \n",
    "    Args:\n",
    "        values: array of possible values the random variable can take\n",
    "        probabilities: corresponding probabilities for each value\n",
    "    \n",
    "    Returns:\n",
    "        expected value and variance\n",
    "    \"\"\"\n",
    "    # Validate inputs\n",
    "    if len(values) != len(probabilities) or abs(sum(probabilities) - 1) > 1e-10:\n",
    "        raise ValueError(\"Values and probabilities must have the same length, and probabilities must sum to 1\")\n",
    "    \n",
    "    # Calculate expected value\n",
    "    expected_value = np.sum(values * probabilities)\n",
    "    \n",
    "    # Calculate variance\n",
    "    variance = np.sum((values - expected_value)**2 * probabilities)\n",
    "    \n",
    "    return expected_value, variance\n",
    "\n",
    "# Examples of discrete random variables\n",
    "print(\"=== Expected Value and Variance for Discrete Random Variables ===\\n\")\n",
    "\n",
    "# Example 1: Fair die\n",
    "die_values = np.array([1, 2, 3, 4, 5, 6])\n",
    "die_probs = np.array([1/6, 1/6, 1/6, 1/6, 1/6, 1/6])\n",
    "die_ev, die_var = discrete_expectation_variance(die_values, die_probs)\n",
    "\n",
    "print(\"Fair Die:\")\n",
    "print(f\"Expected Value: {die_ev}\")\n",
    "print(f\"Variance: {die_var}\")\n",
    "print(f\"Standard Deviation: {np.sqrt(die_var)}\\n\")\n",
    "\n",
    "# Example 2: Weighted die (loaded to favor 6)\n",
    "weighted_die_values = np.array([1, 2, 3, 4, 5, 6])\n",
    "weighted_die_probs = np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.5])\n",
    "weighted_die_ev, weighted_die_var = discrete_expectation_variance(weighted_die_values, weighted_die_probs)\n",
    "\n",
    "print(\"Weighted Die (favoring 6):\")\n",
    "print(f\"Expected Value: {weighted_die_ev}\")\n",
    "print(f\"Variance: {weighted_die_var}\")\n",
    "print(f\"Standard Deviation: {np.sqrt(weighted_die_var)}\\n\")\n",
    "\n",
    "# Example 3: Number of heads in 3 fair coin tosses\n",
    "coin_values = np.array([0, 1, 2, 3])  # 0, 1, 2, or 3 heads\n",
    "coin_probs = np.array([1/8, 3/8, 3/8, 1/8])  # binomial probabilities\n",
    "coin_ev, coin_var = discrete_expectation_variance(coin_values, coin_probs)\n",
    "\n",
    "print(\"Number of Heads in 3 Fair Coin Tosses:\")\n",
    "print(f\"Expected Value: {coin_ev}\")\n",
    "print(f\"Variance: {coin_var}\")\n",
    "print(f\"Standard Deviation: {np.sqrt(coin_var)}\\n\")\n",
    "\n",
    "# Visualize these random variables\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Fair die\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.bar(die_values, die_probs, alpha=0.7)\n",
    "plt.axvline(x=die_ev, color='r', linestyle='--', label=f'Mean = {die_ev}')\n",
    "plt.title('Fair Die')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()\n",
    "\n",
    "# Weighted die\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.bar(weighted_die_values, weighted_die_probs, alpha=0.7)\n",
    "plt.axvline(x=weighted_die_ev, color='r', linestyle='--', label=f'Mean = {weighted_die_ev:.2f}')\n",
    "plt.title('Weighted Die')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()\n",
    "\n",
    "# Coin tosses\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.bar(coin_values, coin_probs, alpha=0.7)\n",
    "plt.axvline(x=coin_ev, color='r', linestyle='--', label=f'Mean = {coin_ev}')\n",
    "plt.title('Number of Heads in 3 Fair Coin Tosses')\n",
    "plt.xlabel('Number of Heads')\n",
    "plt.ylabel('Probability')\n",
    "plt.xticks(coin_values)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Demonstrate Law of Large Numbers\n",
    "def law_of_large_numbers_demo(random_var_fn, true_mean, n_samples=10000, title=\"Law of Large Numbers\"):\n",
    "    \"\"\"\n",
    "    Visualize the Law of Large Numbers.\n",
    "    \n",
    "    Args:\n",
    "        random_var_fn: function that generates random samples\n",
    "        true_mean: the theoretical mean of the distribution\n",
    "        n_samples: number of samples to generate\n",
    "        title: title for the plot\n",
    "    \"\"\"\n",
    "    # Generate samples\n",
    "    samples = random_var_fn(n_samples)\n",
    "    \n",
    "    # Calculate running mean\n",
    "    running_mean = np.cumsum(samples) / np.arange(1, n_samples+1)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(running_mean, 'b-', alpha=0.7)\n",
    "    plt.axhline(y=true_mean, color='r', linestyle='--', label=f'True Mean = {true_mean}')\n",
    "    plt.xscale('log')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Number of Samples')\n",
    "    plt.ylabel('Sample Mean')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Final sample mean after {n_samples} samples: {running_mean[-1]:.6f}\")\n",
    "    print(f\"True mean: {true_mean:.6f}\")\n",
    "    print(f\"Difference: {abs(running_mean[-1] - true_mean):.6f}\")\n",
    "\n",
    "# Demonstrate LLN with fair die rolls\n",
    "print(\"\\n=== Law of Large Numbers Demonstration ===\")\n",
    "law_of_large_numbers_demo(\n",
    "    lambda n: np.random.randint(1, 7, size=n),\n",
    "    true_mean=3.5,\n",
    "    title=\"Law of Large Numbers: Fair Die Rolls\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cac330",
   "metadata": {},
   "source": [
    "## 7. Bayes' Theorem and Applications\n",
    "\n",
    "Bayes' theorem provides a way to update our belief about the probability of an event based on new evidence. The theorem is stated as:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n",
    "\n",
    "Where:\n",
    "- P(A|B) is the posterior probability: the probability of hypothesis A given the data B\n",
    "- P(B|A) is the likelihood: the probability of data B given hypothesis A\n",
    "- P(A) is the prior probability: our initial belief about the probability of A\n",
    "- P(B) is the marginal likelihood: the total probability of observing data B\n",
    "\n",
    "This theorem is foundational for many machine learning algorithms, especially in Bayesian statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0eda84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrating Bayes' Theorem with a medical test example\n",
    "def bayes_theorem_medical_test():\n",
    "    \"\"\"\n",
    "    Example: Medical Test\n",
    "    - Disease prevalence: 1% (prior)\n",
    "    - Test sensitivity: 95% (true positive rate) - P(positive | disease)\n",
    "    - Test specificity: 90% (true negative rate) - P(negative | no disease)\n",
    "    \n",
    "    Question: If a person tests positive, what's the probability they have the disease?\n",
    "    \"\"\"\n",
    "    # Given information\n",
    "    prior_probability = 0.01  # P(D) - prevalence of disease\n",
    "    sensitivity = 0.95        # P(+ | D) - test sensitivity\n",
    "    specificity = 0.90        # P(- | not D) - test specificity\n",
    "    \n",
    "    # Calculate false positive rate\n",
    "    false_positive_rate = 1 - specificity  # P(+ | not D)\n",
    "    \n",
    "    # Calculate marginal likelihood - P(+)\n",
    "    marginal = (sensitivity * prior_probability) + (false_positive_rate * (1 - prior_probability))\n",
    "    \n",
    "    # Calculate posterior using Bayes' theorem - P(D | +)\n",
    "    posterior = (sensitivity * prior_probability) / marginal\n",
    "    \n",
    "    print(\"=== Medical Test Example ===\")\n",
    "    print(f\"Disease prevalence: {prior_probability:.1%}\")\n",
    "    print(f\"Test sensitivity: {sensitivity:.1%}\")\n",
    "    print(f\"Test specificity: {specificity:.1%}\")\n",
    "    print(f\"Probability of testing positive: {marginal:.2%}\")\n",
    "    print(f\"Probability of having disease given positive test: {posterior:.2%}\")\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot the probability tree\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.axis('off')\n",
    "    plt.text(0.5, 0.9, 'Population', ha='center', fontsize=14, fontweight='bold')\n",
    "    plt.text(0.3, 0.7, f'Disease\\n{prior_probability:.1%}', ha='center', fontsize=12)\n",
    "    plt.text(0.7, 0.7, f'No Disease\\n{(1-prior_probability):.1%}', ha='center', fontsize=12)\n",
    "    plt.text(0.2, 0.5, f'Test +\\n{sensitivity:.1%}', ha='center', fontsize=10)\n",
    "    plt.text(0.4, 0.5, f'Test -\\n{(1-sensitivity):.1%}', ha='center', fontsize=10)\n",
    "    plt.text(0.6, 0.5, f'Test +\\n{false_positive_rate:.1%}', ha='center', fontsize=10)\n",
    "    plt.text(0.8, 0.5, f'Test -\\n{specificity:.1%}', ha='center', fontsize=10)\n",
    "    \n",
    "    # Draw tree lines\n",
    "    plt.plot([0.5, 0.3], [0.88, 0.75], 'k-')\n",
    "    plt.plot([0.5, 0.7], [0.88, 0.75], 'k-')\n",
    "    plt.plot([0.3, 0.2], [0.68, 0.55], 'k-')\n",
    "    plt.plot([0.3, 0.4], [0.68, 0.55], 'k-')\n",
    "    plt.plot([0.7, 0.6], [0.68, 0.55], 'k-')\n",
    "    plt.plot([0.7, 0.8], [0.68, 0.55], 'k-')\n",
    "    \n",
    "    # Create a table for the joint distribution\n",
    "    plt.subplot(1, 2, 2)\n",
    "    # Calculate joint probabilities\n",
    "    p_disease_positive = prior_probability * sensitivity\n",
    "    p_disease_negative = prior_probability * (1 - sensitivity)\n",
    "    p_no_disease_positive = (1 - prior_probability) * false_positive_rate\n",
    "    p_no_disease_negative = (1 - prior_probability) * specificity\n",
    "    \n",
    "    data = [\n",
    "        ['', 'Disease', 'No Disease', 'Total'],\n",
    "        ['Test +', f'{p_disease_positive:.2%}', f'{p_no_disease_positive:.2%}', f'{p_disease_positive + p_no_disease_positive:.2%}'],\n",
    "        ['Test -', f'{p_disease_negative:.2%}', f'{p_no_disease_negative:.2%}', f'{p_disease_negative + p_no_disease_negative:.2%}'],\n",
    "        ['Total', f'{prior_probability:.2%}', f'{1-prior_probability:.2%}', '100%']\n",
    "    ]\n",
    "    \n",
    "    plt.table(cellText=data, loc='center', cellLoc='center', edges='closed')\n",
    "    plt.axis('off')\n",
    "    plt.title('Joint Probability Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return posterior\n",
    "\n",
    "# Run the Bayes' theorem example\n",
    "posterior_medical = bayes_theorem_medical_test()\n",
    "\n",
    "# Bayesian updating example\n",
    "def bayesian_updating(prior_belief, data_likelihood, steps=5):\n",
    "    \"\"\"\n",
    "    Demonstrate Bayesian updating - how our belief changes as we observe more data.\n",
    "    \n",
    "    Args:\n",
    "        prior_belief: initial probability of hypothesis being true\n",
    "        data_likelihood: tuple (P(data|H), P(data|not H))\n",
    "        steps: number of data points to observe\n",
    "    \"\"\"\n",
    "    # Store beliefs over time\n",
    "    beliefs = [prior_belief]\n",
    "    posterior = prior_belief\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Initial belief\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    \n",
    "    # Plot initial beta distribution (we'll use Beta(1,1) which is uniform)\n",
    "    alpha, beta = 1, 1\n",
    "    plt.plot(x, stats.beta.pdf(x, alpha, beta), 'b-', lw=2, alpha=0.3, \n",
    "             label=f'Prior: Beta({alpha}, {beta})')\n",
    "    \n",
    "    # Simulate observing data and updating beliefs\n",
    "    for i in range(steps):\n",
    "        # Generate random data (biased towards hypothesis being true)\n",
    "        data_observed = np.random.random() < data_likelihood[0]\n",
    "        \n",
    "        # Calculate likelihood of observed data\n",
    "        if data_observed:\n",
    "            likelihood = data_likelihood[0] if posterior > 0.5 else data_likelihood[1]\n",
    "            alpha += 1  # Add a success\n",
    "        else:\n",
    "            likelihood = 1 - data_likelihood[0] if posterior > 0.5 else 1 - data_likelihood[1]\n",
    "            beta += 1  # Add a failure\n",
    "        \n",
    "        # Calculate marginal likelihood\n",
    "        marginal = likelihood * posterior + (1 - likelihood) * (1 - posterior)\n",
    "        \n",
    "        # Update posterior using Bayes' theorem\n",
    "        posterior = (likelihood * posterior) / marginal\n",
    "        beliefs.append(posterior)\n",
    "        \n",
    "        # Plot updated beta distribution\n",
    "        if i == steps - 1:\n",
    "            plt.plot(x, stats.beta.pdf(x, alpha, beta), 'r-', lw=2,\n",
    "                     label=f'Posterior: Beta({alpha}, {beta})')\n",
    "        else:\n",
    "            plt.plot(x, stats.beta.pdf(x, alpha, beta), 'g-', lw=1, alpha=0.5)\n",
    "    \n",
    "    plt.title('Bayesian Updating of Beliefs')\n",
    "    plt.xlabel('Probability')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot belief over time\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(len(beliefs)), beliefs, 'bo-', lw=2)\n",
    "    plt.axhline(y=0.5, color='r', linestyle='--')\n",
    "    plt.title('Belief Evolution Over Time')\n",
    "    plt.xlabel('Number of Observations')\n",
    "    plt.ylabel('Probability of Hypothesis Being True')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Initial belief: {prior_belief:.4f}\")\n",
    "    print(f\"Final belief after {steps} observations: {posterior:.4f}\")\n",
    "    \n",
    "    return posterior\n",
    "\n",
    "# Demonstrate Bayesian updating\n",
    "print(\"\\n=== Bayesian Updating Example ===\")\n",
    "print(\"Scenario: Testing whether a coin is fair or biased\")\n",
    "bayesian_updating(\n",
    "    prior_belief=0.5,  # Initial belief: 50% chance coin is fair\n",
    "    data_likelihood=(0.7, 0.3),  # P(heads|fair) = 0.5, P(heads|biased) = 0.7\n",
    "    steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5fc1cc",
   "metadata": {},
   "source": [
    "## 8. Probability in Data Science Applications\n",
    "\n",
    "Probability is foundational in many data science techniques. Let's explore some practical applications:\n",
    "\n",
    "1. **Risk Assessment**: Using probability to quantify and manage uncertainty\n",
    "2. **A/B Testing**: Statistical hypothesis testing to compare two versions\n",
    "3. **Predictive Modeling**: Using probability distributions to make predictions\n",
    "4. **Anomaly Detection**: Identifying rare events using probability thresholds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
