{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aggregation and Grouping in Pandas\n",
    "\n",
    "Data aggregation and grouping are fundamental techniques in data analysis that allow us to summarize and extract insights from large datasets. These operations transform raw data into meaningful information by organizing data into groups and calculating summary statistics.\n",
    "\n",
    "In this notebook, we'll explore how to:\n",
    "- Use groupby operations in pandas\n",
    "- Apply aggregation functions\n",
    "- Work with multiple grouping variables\n",
    "- Perform complex aggregations\n",
    "- Transform and filter grouped data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plot styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('colorblind')\n",
    "\n",
    "# For better display of dataframes\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Sample Data\n",
    "\n",
    "Let's create a realistic dataset to work with throughout this notebook. We'll simulate a sales dataset with different products, regions, dates, and sales figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create date range for the past year\n",
    "dates = pd.date_range(start='2024-01-01', end='2024-04-01', freq='D')\n",
    "\n",
    "# Define categories\n",
    "products = ['Laptop', 'Smartphone', 'Tablet', 'Headphones', 'Smartwatch']\n",
    "regions = ['North', 'South', 'East', 'West', 'Central']\n",
    "payment_methods = ['Credit Card', 'Debit Card', 'PayPal', 'Cash']\n",
    "\n",
    "# Generate random data\n",
    "n_records = 1000\n",
    "data = {\n",
    "    'date': np.random.choice(dates, n_records),\n",
    "    'product': np.random.choice(products, n_records),\n",
    "    'region': np.random.choice(regions, n_records),\n",
    "    'units_sold': np.random.randint(1, 20, n_records),\n",
    "    'unit_price': np.random.uniform(100, 2000, n_records).round(2),\n",
    "    'customer_age': np.random.randint(18, 70, n_records),\n",
    "    'payment_method': np.random.choice(payment_methods, n_records),\n",
    "    'discount_applied': np.random.choice([True, False], n_records, p=[0.3, 0.7])\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "sales_df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate total sale amount\n",
    "sales_df['sales_amount'] = sales_df['units_sold'] * sales_df['unit_price']\n",
    "# Apply discount where applicable\n",
    "sales_df.loc[sales_df['discount_applied'], 'sales_amount'] *= 0.9\n",
    "\n",
    "# Display the first few rows\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our data structure and basic information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Grouping and Aggregation\n",
    "\n",
    "The `groupby()` function in pandas is the foundation for aggregation operations. It splits the data into groups based on specified columns and allows for computations on these groups.\n",
    "\n",
    "### 3.1 Simple Grouping with a Single Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by region and calculate the sum of sales\n",
    "region_sales = sales_df.groupby('region')['sales_amount'].sum().reset_index()\n",
    "region_sales.sort_values('sales_amount', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='region', y='sales_amount', data=region_sales)\n",
    "plt.title('Total Sales by Region')\n",
    "plt.ylabel('Total Sales ($)')\n",
    "plt.xlabel('Region')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Using Different Aggregation Functions\n",
    "\n",
    "Pandas provides many built-in aggregation functions like `sum()`, `mean()`, `count()`, `min()`, `max()`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by product and calculate multiple statistics\n",
    "product_stats = sales_df.groupby('product').agg({\n",
    "    'sales_amount': ['sum', 'mean', 'count'],\n",
    "    'units_sold': ['sum', 'mean', 'max']\n",
    "}).round(2)\n",
    "\n",
    "product_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can flatten the multi-level column index for easier viewing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the multi-level column index\n",
    "product_stats.columns = ['_'.join(col).strip() for col in product_stats.columns.values]\n",
    "product_stats.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Using Custom Aggregation Functions\n",
    "\n",
    "We can also use custom functions with `agg()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to calculate the range\n",
    "def sales_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "# Calculate the median, range, and percentiles\n",
    "product_custom_agg = sales_df.groupby('product')['sales_amount'].agg([\n",
    "    ('median', 'median'),\n",
    "    ('range', sales_range),\n",
    "    ('percentile_25', lambda x: np.percentile(x, 25)),\n",
    "    ('percentile_75', lambda x: np.percentile(x, 75))\n",
    "]).round(2)\n",
    "\n",
    "product_custom_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Grouping with Multiple Columns\n",
    "\n",
    "Often, we need to group data by more than one column to get more detailed insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by both region and product\n",
    "region_product_sales = sales_df.groupby(['region', 'product'])['sales_amount'].sum().reset_index()\n",
    "region_product_sales.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table for better visualization\n",
    "sales_pivot = region_product_sales.pivot_table(index='region', columns='product', values='sales_amount')\n",
    "sales_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize with a heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(sales_pivot, annot=True, fmt='.0f', cmap='YlGnBu')\n",
    "plt.title('Sales Amount by Region and Product')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Unstacking Grouped Results\n",
    "\n",
    "When grouping by multiple columns, we can use `unstack()` to convert one level of index to columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by region and payment method, then unstack\n",
    "payment_by_region = sales_df.groupby(['region', 'payment_method'])['sales_amount'].sum().unstack()\n",
    "payment_by_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize as a stacked bar chart\n",
    "payment_by_region.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "plt.title('Sales by Region and Payment Method')\n",
    "plt.ylabel('Sales Amount ($)')\n",
    "plt.xlabel('Region')\n",
    "plt.legend(title='Payment Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The Split-Apply-Combine Pattern\n",
    "\n",
    "GroupBy operations follow the split-apply-combine pattern:\n",
    "1. **Split**: Data is split into groups based on key(s)\n",
    "2. **Apply**: A function is applied to each group independently\n",
    "3. **Combine**: The results are combined into a new data structure\n",
    "\n",
    "Let's see a more complex example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract month from date\n",
    "sales_df['month'] = sales_df['date'].dt.month_name()\n",
    "\n",
    "# Group by month and calculate multiple aggregations for different columns\n",
    "monthly_stats = sales_df.groupby('month').agg({\n",
    "    'sales_amount': ['sum', 'mean', 'count'],\n",
    "    'units_sold': 'sum',\n",
    "    'customer_age': ['mean', 'median', 'min', 'max'],\n",
    "    'discount_applied': 'sum'  # Counts True values (discounted sales)\n",
    "})\n",
    "\n",
    "# Flatten the columns\n",
    "monthly_stats.columns = ['_'.join(col).strip() for col in monthly_stats.columns.values]\n",
    "\n",
    "# Calculate additional metrics\n",
    "monthly_stats['pct_discounted'] = (monthly_stats['discount_applied_sum'] / monthly_stats['sales_amount_count'] * 100).round(1)\n",
    "monthly_stats['avg_sale_per_unit'] = (monthly_stats['sales_amount_sum'] / monthly_stats['units_sold_sum']).round(2)\n",
    "\n",
    "# Sort by month order (not alphabetical)\n",
    "month_order = ['January', 'February', 'March', 'April']\n",
    "monthly_stats = monthly_stats.reindex(month_order)\n",
    "\n",
    "monthly_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Groupby Operations\n",
    "\n",
    "### 6.1 Filtering Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter groups based on a condition\n",
    "# Find products where the average sales amount is greater than 10000\n",
    "high_value_products = sales_df.groupby('product').filter(lambda x: x['sales_amount'].mean() > 10000)\n",
    "\n",
    "# Count records by product in the filtered dataset\n",
    "high_value_products['product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Transforming Groups\n",
    "\n",
    "The `transform()` method applies a function to each group and returns a result with the same shape as the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with the mean sales amount for each product\n",
    "sales_df['product_avg_sales'] = sales_df.groupby('product')['sales_amount'].transform('mean')\n",
    "\n",
    "# Calculate how each sale compares to its product average\n",
    "sales_df['sales_vs_avg'] = sales_df['sales_amount'] - sales_df['product_avg_sales']\n",
    "sales_df['sales_vs_avg_pct'] = (sales_df['sales_vs_avg'] / sales_df['product_avg_sales'] * 100).round(1)\n",
    "\n",
    "# Show a sample of the results\n",
    "sales_df[['product', 'sales_amount', 'product_avg_sales', 'sales_vs_avg', 'sales_vs_avg_pct']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Applying Functions to Groups\n",
    "\n",
    "The `apply()` method applies a function to each group and returns a result for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 2 sales in each region\n",
    "def get_top_n(group, n=2):\n",
    "    return group.nlargest(n, 'sales_amount')\n",
    "\n",
    "top_sales_by_region = sales_df.groupby('region').apply(get_top_n)\n",
    "top_sales_by_region[['region', 'product', 'sales_amount', 'date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Aggregation with Pivot Tables\n",
    "\n",
    "Pivot tables provide a convenient way to summarize data with a more flexible layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table: products by month with sales amounts\n",
    "pivot = pd.pivot_table(\n",
    "    sales_df, \n",
    "    values='sales_amount', \n",
    "    index='product',\n",
    "    columns='month', \n",
    "    aggfunc='sum'\n",
    ")\n",
    "\n",
    "# Reorder columns by month\n",
    "pivot = pivot[month_order]\n",
    "\n",
    "# Add row totals\n",
    "pivot['Total'] = pivot.sum(axis=1)\n",
    "\n",
    "# Add column percentages\n",
    "for month in month_order:\n",
    "    pivot[f'{month} %'] = (pivot[month] / pivot['Total'] * 100).round(1)\n",
    "\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Multi-level Pivot Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multi-level pivot table\n",
    "multi_pivot = pd.pivot_table(\n",
    "    sales_df,\n",
    "    values=['sales_amount', 'units_sold'],\n",
    "    index=['region', 'product'],\n",
    "    columns='month',\n",
    "    aggfunc={'sales_amount': 'sum', 'units_sold': 'sum'},\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Show a portion of the table\n",
    "multi_pivot.loc[('North',), :].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Time-Based Grouping and Resampling\n",
    "\n",
    "For time series data, we can use the `resample()` method to group by date/time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the date as index\n",
    "time_series = sales_df.set_index('date')\n",
    "\n",
    "# Resample by week and calculate sum of sales\n",
    "weekly_sales = time_series.resample('W')['sales_amount'].sum()\n",
    "\n",
    "# Plot the time series\n",
    "plt.figure(figsize=(14, 6))\n",
    "weekly_sales.plot()\n",
    "plt.title('Weekly Sales Trends')\n",
    "plt.ylabel('Total Sales ($)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Practical Example: Sales Dashboard\n",
    "\n",
    "Let's combine several aggregation techniques to create a sales analysis dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate overall sales metrics\n",
    "total_sales = sales_df['sales_amount'].sum()\n",
    "total_units = sales_df['units_sold'].sum()\n",
    "avg_sale = sales_df['sales_amount'].mean()\n",
    "num_transactions = len(sales_df)\n",
    "\n",
    "# 2. Product performance\n",
    "product_perf = sales_df.groupby('product').agg({\n",
    "    'sales_amount': ['sum', 'mean', 'count'],\n",
    "    'units_sold': 'sum'\n",
    "}).round(2)\n",
    "product_perf.columns = ['_'.join(col).strip() for col in product_perf.columns.values]\n",
    "product_perf['avg_price'] = (product_perf['sales_amount_sum'] / product_perf['units_sold_sum']).round(2)\n",
    "product_perf['sales_pct'] = (product_perf['sales_amount_sum'] / total_sales * 100).round(1)\n",
    "product_perf = product_perf.sort_values('sales_amount_sum', ascending=False)\n",
    "\n",
    "# 3. Regional performance\n",
    "region_perf = sales_df.groupby('region').agg({\n",
    "    'sales_amount': ['sum', 'mean', 'count'],\n",
    "    'units_sold': 'sum',\n",
    "    'discount_applied': 'sum'\n",
    "}).round(2)\n",
    "region_perf.columns = ['_'.join(col).strip() for col in region_perf.columns.values]\n",
    "region_perf['discount_rate'] = (region_perf['discount_applied_sum'] / region_perf['sales_amount_count'] * 100).round(1)\n",
    "region_perf = region_perf.sort_values('sales_amount_sum', ascending=False)\n",
    "\n",
    "# 4. Time analysis\n",
    "time_series = sales_df.set_index('date')\n",
    "daily_sales = time_series.resample('D')['sales_amount'].sum()\n",
    "\n",
    "# 5. Payment method analysis\n",
    "payment_analysis = sales_df.groupby('payment_method').agg({\n",
    "    'sales_amount': ['sum', 'mean', 'count'],\n",
    "    'customer_age': 'mean'\n",
    "}).round(2)\n",
    "payment_analysis.columns = ['_'.join(col).strip() for col in payment_analysis.columns.values]\n",
    "payment_analysis['pct_of_transactions'] = (payment_analysis['sales_amount_count'] / num_transactions * 100).round(1)\n",
    "payment_analysis = payment_analysis.sort_values('sales_amount_sum', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Dashboard: Key Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Sales: ${total_sales:,.2f}\")\n",
    "print(f\"Number of Transactions: {num_transactions:,}\")\n",
    "print(f\"Average Sale Amount: ${avg_sale:,.2f}\")\n",
    "print(f\"Total Units Sold: {total_units:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Dashboard: Product Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize product performance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=product_perf.index, y='sales_amount_sum', data=product_perf)\n",
    "plt.title('Total Sales by Product')\n",
    "plt.ylabel('Total Sales ($)')\n",
    "plt.xlabel('Product')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Dashboard: Regional Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regional performance\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.barplot(x=region_perf.index, y='sales_amount_sum', data=region_perf, ax=ax1)\n",
    "ax1.set_title('Total Sales by Region')\n",
    "ax1.set_ylabel('Total Sales ($)')\n",
    "ax1.set_xlabel('Region')\n",
    "\n",
    "sns.barplot(x=region_perf.index, y='discount_rate', data=region_perf, ax=ax2)\n",
    "ax2.set_title('Discount Rate by Region')\n",
    "ax2.set_ylabel('Discount Rate (%)')\n",
    "ax2.set_xlabel('Region')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Dashboard: Payment Method Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot payment methods\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(\n",
    "    payment_analysis['sales_amount_sum'], \n",
    "    labels=payment_analysis.index, \n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90,\n",
    "    explode=[0.05, 0, 0, 0]  # Explode the first slice\n",
    ")\n",
    "plt.title('Sales Amount by Payment Method')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Dashboard: Time Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time trends\n",
    "plt.figure(figsize=(14, 6))\n",
    "daily_sales.plot()\n",
    "plt.title('Daily Sales Trends')\n",
    "plt.ylabel('Sales Amount ($)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion and Best Practices\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **The Split-Apply-Combine Pattern**: GroupBy operations follow this pattern, splitting data into groups, applying functions, then combining results.\n",
    "\n",
    "2. **Multiple Aggregations**: Use `agg()` to apply multiple aggregation functions to different columns.\n",
    "\n",
    "3. **Transformation vs. Aggregation**: \n",
    "   - `transform()` returns data with the same shape as the input\n",
    "   - `agg()` returns one row per group\n",
    "   - `apply()` provides the most flexibility for custom operations\n",
    "\n",
    "4. **Pivot Tables**: Provide a convenient way to reshape data for analysis.\n",
    "\n",
    "5. **Time-Based Grouping**: Use `resample()` for time series data.\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. **Chain Operations Carefully**: GroupBy operations can be chained, but be mindful of performance.\n",
    "\n",
    "2. **Flatten Multi-Index Columns**: After complex aggregations, flatten multi-index columns for easier handling.\n",
    "\n",
    "3. **Use Descriptive Column Names**: When creating new columns from aggregations, use clear names.\n",
    "\n",
    "4. **Consider Performance**: For very large datasets, consider more efficient approaches like:\n",
    "   - Using the `numba` library for custom aggregations\n",
    "   - Using dask or PySpark for distributed computing\n",
    "\n",
    "5. **Visualize Results**: Always visualize aggregated data to better understand patterns and insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Exercises\n",
    "\n",
    "1. Calculate the average age of customers for each product and region combination.\n",
    "\n",
    "2. Identify which day of the week has the highest average sales.\n",
    "\n",
    "3. Find the top 3 products in each region based on units sold.\n",
    "\n",
    "4. Create a rolling 7-day average of sales and plot it.\n",
    "\n",
    "5. Calculate what percentage of total sales each product represents in each region."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
