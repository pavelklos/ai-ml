{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adb69de2",
   "metadata": {},
   "source": [
    "# Pandas DataFrame Basics for Data Science\n",
    "\n",
    "This notebook provides a comprehensive introduction to working with pandas DataFrames, one of the most essential data structures for data analysis and manipulation in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4e3735",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "First, let's import pandas and other necessary libraries for working with DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031effdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Display settings for better visualization\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# Check the versions\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c9afb5",
   "metadata": {},
   "source": [
    "## Creating DataFrames\n",
    "\n",
    "There are multiple ways to create pandas DataFrames. Let's explore the most common methods:\n",
    "1. From dictionaries\n",
    "2. From lists\n",
    "3. From external files (CSV, Excel)\n",
    "4. From other data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5271cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Creating DataFrame from a dictionary\n",
    "data_dict = {\n",
    "    'Name': ['John', 'Anna', 'Peter', 'Linda'],\n",
    "    'Age': [28, 34, 29, 42],\n",
    "    'City': ['New York', 'Paris', 'Berlin', 'London'],\n",
    "    'Salary': [65000, 70000, 62000, 85000]\n",
    "}\n",
    "\n",
    "df_dict = pd.DataFrame(data_dict)\n",
    "print(\"DataFrame from dictionary:\")\n",
    "display(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Creating DataFrame from lists\n",
    "data_list = [\n",
    "    ['John', 28, 'New York', 65000],\n",
    "    ['Anna', 34, 'Paris', 70000],\n",
    "    ['Peter', 29, 'Berlin', 62000],\n",
    "    ['Linda', 42, 'London', 85000]\n",
    "]\n",
    "\n",
    "column_names = ['Name', 'Age', 'City', 'Salary']\n",
    "\n",
    "df_list = pd.DataFrame(data_list, columns=column_names)\n",
    "print(\"\\nDataFrame from list:\")\n",
    "display(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984af9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Creating DataFrame from CSV (let's create a CSV file first)\n",
    "df_dict.to_csv('sample_data.csv', index=False)\n",
    "\n",
    "# Now read it back\n",
    "df_csv = pd.read_csv('sample_data.csv')\n",
    "print(\"\\nDataFrame from CSV:\")\n",
    "display(df_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b709cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Creating DataFrame from Excel (let's create an Excel file first)\n",
    "df_dict.to_excel('sample_data.xlsx', index=False)\n",
    "\n",
    "# Now read it back\n",
    "df_excel = pd.read_excel('sample_data.xlsx')\n",
    "print(\"\\nDataFrame from Excel:\")\n",
    "display(df_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Creating DataFrame from NumPy array\n",
    "numpy_array = np.random.randn(5, 4)  # Create a 5x4 array of random numbers\n",
    "df_numpy = pd.DataFrame(numpy_array, columns=['A', 'B', 'C', 'D'])\n",
    "print(\"\\nDataFrame from NumPy array:\")\n",
    "display(df_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c981e",
   "metadata": {},
   "source": [
    "## Exploring DataFrame Structure\n",
    "\n",
    "Once we have a DataFrame, we need to understand its structure and contents. Pandas provides several methods to explore DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e00496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a more substantial DataFrame to work with\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['John', 'Anna', 'Peter', 'Linda', 'Bob', 'Sarah', 'Mike', 'Emma', 'David', 'Kate'],\n",
    "    'Age': [28, 34, 29, 42, 35, 31, 40, 27, 38, 44],\n",
    "    'City': ['New York', 'Paris', 'Berlin', 'London', 'Madrid', 'Rome', 'Tokyo', 'Sydney', 'Toronto', 'Moscow'],\n",
    "    'Department': ['IT', 'HR', 'Sales', 'IT', 'Finance', 'HR', 'Sales', 'IT', 'Finance', 'Sales'],\n",
    "    'Salary': [65000, 70000, 62000, 85000, 72000, 69000, 76000, 68000, 81000, 73000],\n",
    "    'Experience': [3, 7, 4, 12, 8, 5, 10, 2, 9, 14],\n",
    "    'Active': [True, True, False, True, True, False, True, True, False, True]\n",
    "})\n",
    "\n",
    "# Checking the shape (rows, columns)\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "\n",
    "# Get a quick overview of the DataFrame\n",
    "print(\"\\nDataFrame info:\")\n",
    "df.info()\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# Display the last few rows\n",
    "print(\"\\nLast 5 rows:\")\n",
    "display(df.tail())\n",
    "\n",
    "# Display a random sample\n",
    "print(\"\\nRandom sample of 3 rows:\")\n",
    "display(df.sample(3))\n",
    "\n",
    "# Get column names\n",
    "print(f\"\\nColumn names: {df.columns.tolist()}\")\n",
    "\n",
    "# Get data types of each column\n",
    "print(\"\\nData types:\")\n",
    "display(df.dtypes)\n",
    "\n",
    "# Get basic statistics for numeric columns\n",
    "print(\"\\nBasic statistics:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Include statistics for non-numeric columns as well\n",
    "print(\"\\nBasic statistics for all columns:\")\n",
    "display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c03a1b3",
   "metadata": {},
   "source": [
    "## Basic Data Selection and Filtering\n",
    "\n",
    "Pandas offers multiple ways to select and filter data from DataFrames:\n",
    "1. Column selection\n",
    "2. Using `loc[]` for label-based indexing\n",
    "3. Using `iloc[]` for integer-based indexing\n",
    "4. Boolean indexing\n",
    "5. The `query()` method\n",
    "6. Working with multi-index DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba5f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Column selection\n",
    "# Select a single column (returns a Series)\n",
    "name_series = df['Name']\n",
    "print(\"Single column selection (Series):\")\n",
    "display(name_series.head())\n",
    "\n",
    "# Select multiple columns (returns a DataFrame)\n",
    "subset = df[['Name', 'Age', 'Salary']]\n",
    "print(\"\\nMultiple column selection:\")\n",
    "display(subset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd01efe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Using loc[] for label-based indexing\n",
    "# Select rows by label/index and columns by name\n",
    "print(\"Using loc[] to select specific rows and columns:\")\n",
    "display(df.loc[0:2, ['Name', 'Age', 'City']])\n",
    "\n",
    "# 3. Using iloc[] for integer-based indexing\n",
    "# Select rows and columns by position\n",
    "print(\"\\nUsing iloc[] to select by position:\")\n",
    "display(df.iloc[0:3, 0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c88b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Boolean indexing\n",
    "# Filter rows where Age > 35\n",
    "older_employees = df[df['Age'] > 35]\n",
    "print(\"Employees older than 35:\")\n",
    "display(older_employees)\n",
    "\n",
    "# Filter with multiple conditions\n",
    "it_dept_high_salary = df[(df['Department'] == 'IT') & (df['Salary'] > 70000)]\n",
    "print(\"\\nIT employees with salary > 70000:\")\n",
    "display(it_dept_high_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Using query() method\n",
    "# Same filter as above but using query()\n",
    "query_result = df.query(\"Department == 'IT' and Salary > 70000\")\n",
    "print(\"Using query() method:\")\n",
    "display(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Working with multi-index DataFrames\n",
    "# Create a multi-index DataFrame\n",
    "multi_index_df = df.set_index(['Department', 'City'])\n",
    "print(\"Multi-index DataFrame:\")\n",
    "display(multi_index_df.head())\n",
    "\n",
    "# Select data for a specific index level\n",
    "it_dept = multi_index_df.loc['IT']\n",
    "print(\"\\nJust the IT Department:\")\n",
    "display(it_dept)\n",
    "\n",
    "# Cross-section selection using xs()\n",
    "new_york_employees = multi_index_df.xs('New York', level='City')\n",
    "print(\"\\nEmployees in New York across departments:\")\n",
    "display(new_york_employees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63ac6fc",
   "metadata": {},
   "source": [
    "## Adding and Modifying Data\n",
    "\n",
    "Let's explore how to add and modify data in pandas DataFrames:\n",
    "1. Adding new columns\n",
    "2. Modifying values\n",
    "3. Renaming columns\n",
    "4. Applying functions with `apply()` and `map()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5accba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the original DataFrame to work with\n",
    "df_mod = df.copy()\n",
    "\n",
    "# 1. Adding a new column\n",
    "df_mod['Bonus'] = df_mod['Salary'] * 0.1\n",
    "print(\"DataFrame with new Bonus column:\")\n",
    "display(df_mod.head())\n",
    "\n",
    "# Add a column based on multiple other columns\n",
    "df_mod['Total Compensation'] = df_mod['Salary'] + df_mod['Bonus']\n",
    "display(df_mod[['Name', 'Salary', 'Bonus', 'Total Compensation']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdb4871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Modifying values\n",
    "# Modify a single value\n",
    "df_mod.loc[0, 'Bonus'] = 10000\n",
    "print(\"After modifying a single value:\")\n",
    "display(df_mod.loc[0])\n",
    "\n",
    "# Modify values based on a condition\n",
    "df_mod.loc[df_mod['Experience'] > 10, 'Bonus'] = df_mod['Salary'] * 0.15\n",
    "print(\"\\nAfter increasing bonus for experienced employees:\")\n",
    "display(df_mod[df_mod['Experience'] > 10][['Name', 'Experience', 'Salary', 'Bonus']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02291db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Renaming columns\n",
    "df_mod = df_mod.rename(columns={\n",
    "    'Salary': 'Base Salary',\n",
    "    'Experience': 'Years of Experience'\n",
    "})\n",
    "print(\"After renaming columns:\")\n",
    "display(df_mod.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d439484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Applying functions with apply() and map()\n",
    "# Using apply() on a column - calculate salary per year of experience\n",
    "df_mod['Salary per Year'] = df_mod.apply(\n",
    "    lambda row: row['Base Salary'] / row['Years of Experience'] if row['Years of Experience'] > 0 else 0, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"After adding calculated column with apply():\")\n",
    "display(df_mod[['Name', 'Base Salary', 'Years of Experience', 'Salary per Year']].head())\n",
    "\n",
    "# Using map() to transform a column\n",
    "department_tier = {\n",
    "    'IT': 'Technical',\n",
    "    'HR': 'Administrative',\n",
    "    'Sales': 'Business',\n",
    "    'Finance': 'Business'\n",
    "}\n",
    "\n",
    "df_mod['Department Type'] = df_mod['Department'].map(department_tier)\n",
    "print(\"\\nAfter adding Department Type with map():\")\n",
    "display(df_mod[['Name', 'Department', 'Department Type']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1276377b",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "\n",
    "Missing values are a common issue in real-world datasets. Pandas provides several methods to handle them:\n",
    "1. Detecting missing values\n",
    "2. Removing missing values\n",
    "3. Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a504aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with some missing values\n",
    "df_missing = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': [np.nan, 2, 3, 4, 5],\n",
    "    'C': [1, 2, 3, np.nan, 5],\n",
    "    'D': [np.nan, np.nan, 3, 4, 5]\n",
    "})\n",
    "\n",
    "print(\"DataFrame with missing values:\")\n",
    "display(df_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b55a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Detecting missing values\n",
    "print(\"Missing value check (True means missing):\")\n",
    "display(df_missing.isna())\n",
    "\n",
    "# Count number of missing values in each column\n",
    "print(\"\\nNumber of missing values per column:\")\n",
    "display(df_missing.isna().sum())\n",
    "\n",
    "# Count number of missing values in each row\n",
    "print(\"\\nNumber of missing values per row:\")\n",
    "display(df_missing.isna().sum(axis=1))\n",
    "\n",
    "# Find rows with any missing values\n",
    "print(\"\\nRows with at least one missing value:\")\n",
    "display(df_missing[df_missing.isna().any(axis=1)])\n",
    "\n",
    "# Find columns with any missing values\n",
    "print(\"\\nColumns with missing values:\")\n",
    "missing_cols = df_missing.columns[df_missing.isna().any()]\n",
    "print(missing_cols.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a0dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Removing missing values\n",
    "# Drop rows with any missing values\n",
    "df_dropped = df_missing.dropna()\n",
    "print(\"After dropping rows with missing values:\")\n",
    "display(df_dropped)\n",
    "\n",
    "# Drop rows where all values are missing\n",
    "df_dropped_all = df_missing.dropna(how='all')\n",
    "print(\"\\nAfter dropping rows where all values are missing:\")\n",
    "display(df_dropped_all)\n",
    "\n",
    "# Drop columns with any missing values\n",
    "df_dropped_cols = df_missing.dropna(axis=1)\n",
    "print(\"\\nAfter dropping columns with missing values:\")\n",
    "display(df_dropped_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c450284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Filling missing values\n",
    "# Fill with a specific value\n",
    "df_filled = df_missing.fillna(0)\n",
    "print(\"After filling missing values with 0:\")\n",
    "display(df_filled)\n",
    "\n",
    "# Fill with column means\n",
    "df_filled_mean = df_missing.fillna(df_missing.mean())\n",
    "print(\"\\nAfter filling missing values with column means:\")\n",
    "display(df_filled_mean)\n",
    "\n",
    "# Fill with column medians\n",
    "df_filled_median = df_missing.fillna(df_missing.median())\n",
    "print(\"\\nAfter filling missing values with column medians:\")\n",
    "display(df_filled_median)\n",
    "\n",
    "# Fill forward (use previous value)\n",
    "df_ffill = df_missing.fillna(method='ffill')\n",
    "print(\"\\nAfter forward fill:\")\n",
    "display(df_ffill)\n",
    "\n",
    "# Fill backward (use next value)\n",
    "df_bfill = df_missing.fillna(method='bfill')\n",
    "print(\"\\nAfter backward fill:\")\n",
    "display(df_bfill)\n",
    "\n",
    "# Fill with different values for each column\n",
    "fill_values = {'A': 0, 'B': -1, 'C': 999, 'D': -999}\n",
    "df_fill_dict = df_missing.fillna(value=fill_values)\n",
    "print(\"\\nAfter filling with different values per column:\")\n",
    "display(df_fill_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628bae98",
   "metadata": {},
   "source": [
    "## Basic Statistical Operations\n",
    "\n",
    "Pandas provides built-in methods for statistical operations on DataFrames:\n",
    "1. Core statistical methods\n",
    "2. Using `agg()` for multiple operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c7af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use our original employee DataFrame\n",
    "print(\"Original DataFrame (first 5 rows):\")\n",
    "display(df.head())\n",
    "\n",
    "# 1. Core statistical methods\n",
    "# Calculate the mean of numeric columns\n",
    "print(\"\\nMean values:\")\n",
    "display(df.mean(numeric_only=True))\n",
    "\n",
    "# Calculate the median\n",
    "print(\"\\nMedian values:\")\n",
    "display(df.median(numeric_only=True))\n",
    "\n",
    "# Calculate minimum and maximum\n",
    "print(\"\\nMinimum values:\")\n",
    "display(df.min(numeric_only=True))\n",
    "print(\"\\nMaximum values:\")\n",
    "display(df.max(numeric_only=True))\n",
    "\n",
    "# Calculate standard deviation\n",
    "print(\"\\nStandard deviation:\")\n",
    "display(df.std(numeric_only=True))\n",
    "\n",
    "# Calculate sum\n",
    "print(\"\\nSum of values:\")\n",
    "display(df.sum(numeric_only=True))\n",
    "\n",
    "# Count non-null values\n",
    "print(\"\\nCount of non-null values:\")\n",
    "display(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad72c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Using agg() for multiple operations\n",
    "# Apply multiple functions to numeric columns\n",
    "stats = df.agg(['min', 'max', 'mean', 'median', 'std'])\n",
    "print(\"Multiple statistics with agg():\")\n",
    "display(stats)\n",
    "\n",
    "# Apply different functions to different columns\n",
    "custom_agg = df.agg({\n",
    "    'Age': ['min', 'max', 'mean'],\n",
    "    'Salary': ['mean', 'median', 'std'],\n",
    "    'Experience': ['min', 'max', 'mean']\n",
    "})\n",
    "\n",
    "print(\"\\nCustom aggregations by column:\")\n",
    "display(custom_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between numeric columns\n",
    "corr = df.corr()\n",
    "print(\"Correlation matrix:\")\n",
    "display(corr)\n",
    "\n",
    "# Visualize the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182cd59",
   "metadata": {},
   "source": [
    "## GroupBy Operations\n",
    "\n",
    "The `groupby()` method is a powerful tool for grouped data analysis:\n",
    "1. Basic groupby operations\n",
    "2. Aggregation with groupby\n",
    "3. Transformations with groupby\n",
    "4. Split-apply-combine pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678a42c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Basic groupby operations\n",
    "# Group by a single column\n",
    "dept_groups = df.groupby('Department')\n",
    "\n",
    "# Get the size of each group\n",
    "print(\"Number of employees in each department:\")\n",
    "display(dept_groups.size())\n",
    "\n",
    "# Get basic statistics for each group\n",
    "print(\"\\nBasic statistics for each department:\")\n",
    "display(dept_groups.describe())\n",
    "\n",
    "# Access a specific group\n",
    "print(\"\\nIT Department details:\")\n",
    "display(dept_groups.get_group('IT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e57f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Aggregation with groupby\n",
    "# Calculate mean values for each department\n",
    "dept_means = dept_groups.mean(numeric_only=True)\n",
    "print(\"Mean values for each department:\")\n",
    "display(dept_means)\n",
    "\n",
    "# Apply multiple aggregation functions\n",
    "dept_aggs = dept_groups.agg({\n",
    "    'Age': 'mean',\n",
    "    'Salary': ['mean', 'min', 'max', 'std'],\n",
    "    'Experience': ['mean', 'min', 'max']\n",
    "})\n",
    "\n",
    "print(\"\\nMultiple aggregations by department:\")\n",
    "display(dept_aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8702330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Transformations with groupby\n",
    "# Add a column showing the mean salary for each department\n",
    "df['Dept Average Salary'] = df.groupby('Department')['Salary'].transform('mean')\n",
    "\n",
    "# Calculate the difference between individual salary and department average\n",
    "df['Salary vs Dept Avg'] = df['Salary'] - df['Dept Average Salary']\n",
    "\n",
    "print(\"DataFrame with transformed columns:\")\n",
    "display(df[['Name', 'Department', 'Salary', 'Dept Average Salary', 'Salary vs Dept Avg']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6287d2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Multiple grouping levels\n",
    "# Group by Department and City\n",
    "multi_group = df.groupby(['Department', 'City'])\n",
    "\n",
    "print(\"Number of employees by Department and City:\")\n",
    "display(multi_group.size())\n",
    "\n",
    "print(\"\\nAverage age and salary by Department and City:\")\n",
    "display(multi_group[['Age', 'Salary']].mean())\n",
    "\n",
    "# Filter groups that have more than 1 employee\n",
    "print(\"\\nGroups with more than 1 employee:\")\n",
    "group_filter = multi_group.filter(lambda x: len(x) > 1)\n",
    "display(group_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b98350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the average salary by department\n",
    "avg_salary_by_dept = df.groupby('Department')['Salary'].mean().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "avg_salary_by_dept.plot(kind='bar', color='skyblue')\n",
    "plt.title('Average Salary by Department')\n",
    "plt.xlabel('Department')\n",
    "plt.ylabel('Average Salary ($)')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "for i, v in enumerate(avg_salary_by_dept):\n",
    "    plt.text(i, v + 1000, f\"${v:,.0f}\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5321a953",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook covered the essential operations for working with pandas DataFrames:\n",
    "\n",
    "1. Creating DataFrames from various data sources\n",
    "2. Exploring and understanding DataFrame structure\n",
    "3. Selecting and filtering data using different methods\n",
    "4. Adding and modifying DataFrame content\n",
    "5. Handling missing values effectively\n",
    "6. Performing statistical operations\n",
    "7. Using groupby for aggregated analysis\n",
    "\n",
    "These fundamentals provide a strong foundation for more advanced data analysis and manipulation tasks in Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
