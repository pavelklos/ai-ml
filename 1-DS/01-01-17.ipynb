{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61666a70",
   "metadata": {},
   "source": [
    "# Data Types and Conversions in Data Science\n",
    "\n",
    "This notebook explores various data types in Python, NumPy, and Pandas, along with conversion techniques essential for data science workflows. We'll examine how to efficiently work with different data types, convert between them, and optimize memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c7bc01",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Let's start by importing the essential libraries we'll need for data type operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affc3646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core Python libraries\n",
    "import sys\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "# Import data science libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import utilities for memory analysis\n",
    "from sys import getsizeof\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Print versions for reproducibility\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0f528a",
   "metadata": {},
   "source": [
    "## 2. Understanding Python Data Types\n",
    "\n",
    "Python has several built-in data types that form the foundation for data science operations. Let's explore each of these core data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f275aba",
   "metadata": {},
   "source": [
    "### 2.1 Numeric Types: int, float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a932f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer examples\n",
    "x = 42\n",
    "y = 1000000000000  # Python integers have arbitrary precision\n",
    "\n",
    "# Float examples\n",
    "a = 3.14159\n",
    "b = 2.71828\n",
    "c = 1.0e-10  # Scientific notation\n",
    "\n",
    "# Print types and values\n",
    "print(f\"x = {x}, type: {type(x)}\")\n",
    "print(f\"y = {y}, type: {type(y)}\")\n",
    "print(f\"a = {a}, type: {type(a)}\")\n",
    "print(f\"b = {b}, type: {type(b)}\")\n",
    "print(f\"c = {c}, type: {type(c)}\")\n",
    "\n",
    "# Numeric operations\n",
    "print(f\"\\nOperations:\")\n",
    "print(f\"x + a = {x + a}, type: {type(x + a)}\")  # Note: int + float = float\n",
    "print(f\"a / x = {a / x}, type: {type(a / x)}\")\n",
    "print(f\"x // 5 = {x // 5}, type: {type(x // 5)}\")  # Floor division\n",
    "print(f\"x % 5 = {x % 5}, type: {type(x % 5)}\")  # Modulo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4bd956",
   "metadata": {},
   "source": [
    "### 2.2 Boolean Type: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a208399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean examples\n",
    "t = True\n",
    "f = False\n",
    "\n",
    "# Boolean from comparisons\n",
    "is_greater = x > a\n",
    "is_equal = 10 == 10.0  # True even though types are different\n",
    "\n",
    "print(f\"t = {t}, type: {type(t)}\")\n",
    "print(f\"f = {f}, type: {type(f)}\")\n",
    "print(f\"{x} > {a} = {is_greater}, type: {type(is_greater)}\")\n",
    "print(f\"10 == 10.0: {is_equal}, type: {type(is_equal)}\")\n",
    "\n",
    "# Numeric values of booleans (used in calculations)\n",
    "print(f\"\\nBoolean as numbers:\")\n",
    "print(f\"True + True = {True + True}\")\n",
    "print(f\"int(True) = {int(True)}\")\n",
    "print(f\"int(False) = {int(False)}\")\n",
    "\n",
    "# Boolean operations\n",
    "print(f\"\\nBoolean operations:\")\n",
    "print(f\"True and False = {True and False}\")\n",
    "print(f\"True or False = {True or False}\")\n",
    "print(f\"not True = {not True}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30e3c0",
   "metadata": {},
   "source": [
    "### 2.3 String Type: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df94ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String examples\n",
    "s1 = \"Hello, World!\"\n",
    "s2 = 'Data Science'\n",
    "s3 = \"\"\"Multi-line\n",
    "string example\"\"\"\n",
    "\n",
    "print(f\"s1 = {s1}, type: {type(s1)}\")\n",
    "print(f\"s2 = {s2}, type: {type(s2)}\")\n",
    "print(f\"s3 = {s3}, type: {type(s3)}\")\n",
    "\n",
    "# String operations\n",
    "print(f\"\\nString operations:\")\n",
    "print(f\"Length of s1: {len(s1)}\")\n",
    "print(f\"s1 uppercase: {s1.upper()}\")\n",
    "print(f\"s2 lowercase: {s2.lower()}\")\n",
    "print(f\"Split s1: {s1.split(',')}\")\n",
    "print(f\"Join strings: {'_'.join(['a', 'b', 'c'])}\")\n",
    "print(f\"Replace in s1: {s1.replace('Hello', 'Hi')}\")\n",
    "\n",
    "# String formatting\n",
    "name = \"Python\"\n",
    "version = 3.9\n",
    "print(f\"String formatting: {name} version {version}\")\n",
    "print(\"Old-style formatting: %s version %.1f\" % (name, version))\n",
    "print(\"Format method: {} version {}\".format(name, version))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11f4ded",
   "metadata": {},
   "source": [
    "### 2.4 Container Types: list, tuple, dict, set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8be6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List - mutable ordered collection\n",
    "my_list = [1, 2, 3, 'a', 'b', True]\n",
    "print(f\"my_list = {my_list}, type: {type(my_list)}\")\n",
    "print(f\"First element: {my_list[0]}\")\n",
    "my_list[0] = 100  # Lists are mutable\n",
    "print(f\"After modification: {my_list}\")\n",
    "print(f\"List slice: {my_list[2:5]}\")\n",
    "\n",
    "# Tuple - immutable ordered collection\n",
    "my_tuple = (1, 2, 3, 'a', 'b', True)\n",
    "print(f\"\\nmy_tuple = {my_tuple}, type: {type(my_tuple)}\")\n",
    "print(f\"Second element: {my_tuple[1]}\")\n",
    "# my_tuple[0] = 100  # This would raise an error as tuples are immutable\n",
    "\n",
    "# Dictionary - key-value pairs\n",
    "my_dict = {'name': 'John', 'age': 30, 'city': 'New York'}\n",
    "print(f\"\\nmy_dict = {my_dict}, type: {type(my_dict)}\")\n",
    "print(f\"Access by key: my_dict['name'] = {my_dict['name']}\")\n",
    "my_dict['age'] = 31  # Modify value\n",
    "my_dict['country'] = 'USA'  # Add new key-value pair\n",
    "print(f\"After modification: {my_dict}\")\n",
    "print(f\"Keys: {list(my_dict.keys())}\")\n",
    "print(f\"Values: {list(my_dict.values())}\")\n",
    "print(f\"Items: {list(my_dict.items())}\")\n",
    "\n",
    "# Set - unordered collection of unique elements\n",
    "my_set = {1, 2, 3, 2, 1, 3, 4, 5}  # Duplicates are automatically removed\n",
    "print(f\"\\nmy_set = {my_set}, type: {type(my_set)}\")\n",
    "my_set.add(6)\n",
    "print(f\"After adding 6: {my_set}\")\n",
    "my_set.remove(3)\n",
    "print(f\"After removing 3: {my_set}\")\n",
    "\n",
    "# Set operations\n",
    "set_a = {1, 2, 3, 4}\n",
    "set_b = {3, 4, 5, 6}\n",
    "print(f\"\\nSet operations:\")\n",
    "print(f\"set_a = {set_a}, set_b = {set_b}\")\n",
    "print(f\"Union: {set_a | set_b}\")\n",
    "print(f\"Intersection: {set_a & set_b}\")\n",
    "print(f\"Difference (set_a - set_b): {set_a - set_b}\")\n",
    "print(f\"Symmetric difference: {set_a ^ set_b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39609a8",
   "metadata": {},
   "source": [
    "## 3. NumPy Data Types\n",
    "\n",
    "NumPy introduces a more extensive set of data types that are more memory efficient and better suited for scientific computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f0ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays with different NumPy data types\n",
    "np_int8 = np.array([1, 2, 3], dtype=np.int8)\n",
    "np_int32 = np.array([1, 2, 3], dtype=np.int32)\n",
    "np_int64 = np.array([1, 2, 3], dtype=np.int64)\n",
    "np_float32 = np.array([1.0, 2.0, 3.0], dtype=np.float32)\n",
    "np_float64 = np.array([1.0, 2.0, 3.0], dtype=np.float64)\n",
    "np_bool = np.array([True, False, True], dtype=np.bool_)\n",
    "\n",
    "# Print data types and memory usage\n",
    "print(f\"NumPy int8 array: {np_int8}, dtype: {np_int8.dtype}, itemsize: {np_int8.itemsize} bytes\")\n",
    "print(f\"NumPy int32 array: {np_int32}, dtype: {np_int32.dtype}, itemsize: {np_int32.itemsize} bytes\")\n",
    "print(f\"NumPy int64 array: {np_int64}, dtype: {np_int64.dtype}, itemsize: {np_int64.itemsize} bytes\")\n",
    "print(f\"NumPy float32 array: {np_float32}, dtype: {np_float32.dtype}, itemsize: {np_float32.itemsize} bytes\")\n",
    "print(f\"NumPy float64 array: {np_float64}, dtype: {np_float64.dtype}, itemsize: {np_float64.itemsize} bytes\")\n",
    "print(f\"NumPy bool array: {np_bool}, dtype: {np_bool.dtype}, itemsize: {np_bool.itemsize} bytes\")\n",
    "\n",
    "# Data type ranges\n",
    "print(f\"\\nNumPy data type ranges:\")\n",
    "print(f\"np.int8 range: {np.iinfo(np.int8).min} to {np.iinfo(np.int8).max}\")\n",
    "print(f\"np.uint8 range: {np.iinfo(np.uint8).min} to {np.iinfo(np.uint8).max}\")\n",
    "print(f\"np.int32 range: {np.iinfo(np.int32).min} to {np.iinfo(np.int32).max}\")\n",
    "print(f\"np.int64 range: {np.iinfo(np.int64).min} to {np.iinfo(np.int64).max}\")\n",
    "print(f\"np.float32 range: {np.finfo(np.float32).min} to {np.finfo(np.float32).max}\")\n",
    "print(f\"np.float32 precision: {np.finfo(np.float32).precision} digits\")\n",
    "print(f\"np.float64 range: {np.finfo(np.float64).min} to {np.finfo(np.float64).max}\")\n",
    "print(f\"np.float64 precision: {np.finfo(np.float64).precision} digits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed908e64",
   "metadata": {},
   "source": [
    "### 3.1 Special NumPy Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb3973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex numbers\n",
    "complex_array = np.array([1+2j, 3+4j, 5+6j], dtype=np.complex128)\n",
    "print(f\"Complex array: {complex_array}, dtype: {complex_array.dtype}\")\n",
    "print(f\"Real part: {complex_array.real}\")\n",
    "print(f\"Imaginary part: {complex_array.imag}\")\n",
    "\n",
    "# String data type in NumPy\n",
    "str_array = np.array(['apple', 'banana', 'cherry'], dtype=np.string_)\n",
    "unicode_array = np.array(['apple', 'banana', 'cherry'], dtype=np.unicode_)\n",
    "print(f\"\\nString array: {str_array}, dtype: {str_array.dtype}\")\n",
    "print(f\"Unicode array: {unicode_array}, dtype: {unicode_array.dtype}\")\n",
    "\n",
    "# Datetime data types\n",
    "dates = np.array(['2021-01-01', '2021-01-15', '2021-02-01'], dtype='datetime64')\n",
    "print(f\"\\nDatetime array: {dates}, dtype: {dates.dtype}\")\n",
    "print(f\"Date difference: {dates[1] - dates[0]}\")\n",
    "\n",
    "# Structured arrays (similar to records/structs in other languages)\n",
    "person_type = np.dtype([('name', 'U10'), ('age', 'i4'), ('weight', 'f4')])\n",
    "people = np.array([('Alice', 25, 55.0), ('Bob', 30, 85.5), ('Charlie', 35, 68.0)], dtype=person_type)\n",
    "print(f\"\\nStructured array:\")\n",
    "print(people)\n",
    "print(f\"Names: {people['name']}\")\n",
    "print(f\"Ages: {people['age']}\")\n",
    "print(f\"Average weight: {np.mean(people['weight'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f92be8d",
   "metadata": {},
   "source": [
    "## 4. Pandas Data Types\n",
    "\n",
    "Pandas extends Python and NumPy data types to efficiently handle tabular and time-series data. Let's examine the key Pandas data types and their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8fed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame with different data types\n",
    "data = {\n",
    "    'integer_col': [1, 2, 3, 4, 5],\n",
    "    'float_col': [1.1, 2.2, 3.3, 4.4, 5.5],\n",
    "    'string_col': ['a', 'b', 'c', 'd', 'e'],\n",
    "    'bool_col': [True, False, True, False, True],\n",
    "    'datetime_col': pd.date_range('2021-01-01', periods=5),\n",
    "    'category_col': pd.Categorical(['small', 'medium', 'large', 'small', 'medium']),\n",
    "    'object_col': [{'a': 1}, [1, 2], (3, 4), {5, 6}, 'text']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display DataFrame and data types\n",
    "print(df)\n",
    "print(\"\\nData types in DataFrame:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Info method provides a summary of DataFrame's data types and memory usage\n",
    "print(\"\\nDataFrame info:\")\n",
    "df.info()\n",
    "\n",
    "# Detailed introspection of selected columns\n",
    "print(\"\\nDetailed exploration of columns:\")\n",
    "for col in ['integer_col', 'float_col', 'datetime_col', 'category_col']:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(f\"Type: {type(df[col])}\")\n",
    "    print(f\"Pandas dtype: {df[col].dtype}\")\n",
    "    print(f\"Sample value type: {type(df[col].iloc[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b825bbf8",
   "metadata": {},
   "source": [
    "### 4.1 Pandas Specific Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05da02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical data type\n",
    "# Useful for columns with a limited set of possible values\n",
    "color_series = pd.Series(['red', 'green', 'blue', 'red', 'blue', 'red', 'green'])\n",
    "color_cat = color_series.astype('category')\n",
    "\n",
    "print(f\"Original series: {color_series.dtype}\")\n",
    "print(f\"Categorical series: {color_cat.dtype}\")\n",
    "print(f\"Categories: {color_cat.cat.categories}\")\n",
    "print(f\"Codes: {color_cat.cat.codes}\")\n",
    "print(f\"Memory usage original: {color_series.memory_usage(deep=True)} bytes\")\n",
    "print(f\"Memory usage categorical: {color_cat.memory_usage(deep=True)} bytes\")\n",
    "\n",
    "# Nullable (pandas extension) data types\n",
    "# These provide more consistent handling of missing values\n",
    "df_nullable = pd.DataFrame({\n",
    "    'Int64': pd.Series([1, 2, None, 4], dtype='Int64'),\n",
    "    'Float64': pd.Series([1.1, 2.2, None, 4.4], dtype='Float64'),\n",
    "    'boolean': pd.Series([True, False, None, True], dtype='boolean'),\n",
    "    'string': pd.Series(['a', 'b', None, 'd'], dtype='string')\n",
    "})\n",
    "\n",
    "print(\"\\nDataFrame with nullable/extension types:\")\n",
    "print(df_nullable)\n",
    "print(df_nullable.dtypes)\n",
    "\n",
    "# Date and time data types\n",
    "date_series = pd.Series(pd.date_range('2021-01-01', periods=5))\n",
    "time_series = pd.Series(pd.date_range('00:00:00', periods=5, freq='H'))\n",
    "timedelta_series = pd.Series([pd.Timedelta(days=1), \n",
    "                              pd.Timedelta(hours=2), \n",
    "                              pd.Timedelta(minutes=3)])\n",
    "\n",
    "print(\"\\nDate series:\")\n",
    "print(date_series)\n",
    "print(f\"dtype: {date_series.dtype}\")\n",
    "\n",
    "print(\"\\nTime series:\")\n",
    "print(time_series)\n",
    "print(f\"dtype: {time_series.dtype}\")\n",
    "\n",
    "print(\"\\nTimedelta series:\")\n",
    "print(timedelta_series)\n",
    "print(f\"dtype: {timedelta_series.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a60bb",
   "metadata": {},
   "source": [
    "## 5. Type Checking and Identification\n",
    "\n",
    "Let's explore the different methods to check and identify data types in Python, NumPy, and Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3bb11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python built-in type checking\n",
    "values = [42, 3.14, \"hello\", True, [1, 2, 3], {'a': 1}, (1, 2), {1, 2, 3}]\n",
    "\n",
    "print(\"Python built-in type checking:\")\n",
    "for val in values:\n",
    "    print(f\"Value: {val}, Type: {type(val)}\")\n",
    "\n",
    "# Using isinstance() for type checking\n",
    "print(\"\\nType checking with isinstance():\")\n",
    "print(f\"42 is an integer: {isinstance(42, int)}\")\n",
    "print(f\"3.14 is a float: {isinstance(3.14, float)}\")\n",
    "print(f\"3.14 is a number: {isinstance(3.14, (int, float))}\")  # Check against multiple types\n",
    "print(f\"'hello' is a string: {isinstance('hello', str)}\")\n",
    "print(f\"[1, 2, 3] is a list: {isinstance([1, 2, 3], list)}\")\n",
    "\n",
    "# NumPy type checking\n",
    "numpy_values = [\n",
    "    np.array([1, 2, 3]),\n",
    "    np.array([1.1, 2.2, 3.3]),\n",
    "    np.array(['a', 'b', 'c']),\n",
    "    np.array([True, False, True])\n",
    "]\n",
    "\n",
    "print(\"\\nNumPy type checking:\")\n",
    "for arr in numpy_values:\n",
    "    print(f\"Array: {arr}, dtype: {arr.dtype}\")\n",
    "    print(f\"  Is integer: {np.issubdtype(arr.dtype, np.integer)}\")\n",
    "    print(f\"  Is floating: {np.issubdtype(arr.dtype, np.floating)}\")\n",
    "    print(f\"  Is string: {np.issubdtype(arr.dtype, np.character)}\")\n",
    "    print(f\"  Is boolean: {np.issubdtype(arr.dtype, np.bool_)}\")\n",
    "\n",
    "# Pandas type checking\n",
    "print(\"\\nPandas type checking:\")\n",
    "for col in df.columns:\n",
    "    series = df[col]\n",
    "    print(f\"Column: {col}, dtype: {series.dtype}\")\n",
    "    print(f\"  Is numeric: {pd.api.types.is_numeric_dtype(series)}\")\n",
    "    print(f\"  Is integer: {pd.api.types.is_integer_dtype(series)}\")\n",
    "    print(f\"  Is float: {pd.api.types.is_float_dtype(series)}\")\n",
    "    print(f\"  Is string: {pd.api.types.is_string_dtype(series)}\")\n",
    "    print(f\"  Is boolean: {pd.api.types.is_bool_dtype(series)}\")\n",
    "    print(f\"  Is categorical: {pd.api.types.is_categorical_dtype(series)}\")\n",
    "    print(f\"  Is datetime: {pd.api.types.is_datetime64_any_dtype(series)}\")\n",
    "    print(f\"  Is object: {pd.api.types.is_object_dtype(series)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc1bf3",
   "metadata": {},
   "source": [
    "## 6. Type Conversion in Python\n",
    "\n",
    "Let's explore how to convert between different Python data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc2cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit conversion between numeric types\n",
    "num_int = 123\n",
    "num_float = 123.45\n",
    "num_str = \"456\"\n",
    "num_bool = True\n",
    "\n",
    "print(\"Numeric conversions:\")\n",
    "print(f\"int to float: {float(num_int)}, type: {type(float(num_int))}\")\n",
    "print(f\"float to int: {int(num_float)}, type: {type(int(num_float))}\")  # Truncates, doesn't round\n",
    "print(f\"str to int: {int(num_str)}, type: {type(int(num_str))}\")\n",
    "print(f\"str to float: {float(num_str)}, type: {type(float(num_str))}\")\n",
    "print(f\"bool to int: {int(num_bool)}, type: {type(int(num_bool))}\")\n",
    "print(f\"int to bool: {bool(num_int)}, type: {type(bool(num_int))}\")  # 0 is False, any other number is True\n",
    "print(f\"Zero to bool: {bool(0)}, type: {type(bool(0))}\")\n",
    "\n",
    "# String conversions\n",
    "value_int = 123\n",
    "value_float = 123.45\n",
    "value_bool = False\n",
    "value_list = [1, 2, 3]\n",
    "value_tuple = (4, 5, 6)\n",
    "value_dict = {'a': 1, 'b': 2}\n",
    "value_set = {7, 8, 9}\n",
    "\n",
    "print(\"\\nString conversions:\")\n",
    "print(f\"int to str: {str(value_int)}, type: {type(str(value_int))}\")\n",
    "print(f\"float to str: {str(value_float)}, type: {type(str(value_float))}\")\n",
    "print(f\"bool to str: {str(value_bool)}, type: {type(str(value_bool))}\")\n",
    "print(f\"list to str: {str(value_list)}, type: {type(str(value_list))}\")\n",
    "print(f\"tuple to str: {str(value_tuple)}, type: {type(str(value_tuple))}\")\n",
    "print(f\"dict to str: {str(value_dict)}, type: {type(str(value_dict))}\")\n",
    "print(f\"set to str: {str(value_set)}, type: {type(str(value_set))}\")\n",
    "\n",
    "# Container type conversions\n",
    "sample_str = \"hello\"\n",
    "sample_list = [1, 2, 3, 2, 1]\n",
    "sample_tuple = (4, 5, 6, 5, 4)\n",
    "sample_dict = {'a': 1, 'b': 2, 'c': 3}\n",
    "sample_set = {7, 8, 9}\n",
    "\n",
    "print(\"\\nContainer type conversions:\")\n",
    "print(f\"str to list: {list(sample_str)}, type: {type(list(sample_str))}\")\n",
    "print(f\"list to tuple: {tuple(sample_list)}, type: {type(tuple(sample_list))}\")\n",
    "print(f\"tuple to list: {list(sample_tuple)}, type: {type(list(sample_tuple))}\")\n",
    "print(f\"list to set (removes duplicates): {set(sample_list)}, type: {type(set(sample_list))}\")\n",
    "print(f\"dict to list (gets keys): {list(sample_dict)}, type: {type(list(sample_dict))}\")\n",
    "print(f\"dict to set (gets keys): {set(sample_dict)}, type: {type(set(sample_dict))}\")\n",
    "print(f\"dict items to list: {list(sample_dict.items())}, type: {type(list(sample_dict.items()))}\")\n",
    "\n",
    "# Dictionary creation from sequences\n",
    "keys = ['name', 'age', 'city']\n",
    "values = ['Alice', 30, 'New York']\n",
    "print(\"\\nCreate dict from sequences:\")\n",
    "print(f\"Using zip: {dict(zip(keys, values))}\")\n",
    "print(f\"Using list comprehension: {dict([(keys[i], values[i]) for i in range(len(keys))])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df73d741",
   "metadata": {},
   "source": [
    "### 6.1 Implicit Type Conversion (Type Coercion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91314b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implicit type conversions in Python\n",
    "print(\"Implicit type conversions:\")\n",
    "print(f\"int + float: {10 + 3.5}, type: {type(10 + 3.5)}\")  # int is implicitly converted to float\n",
    "print(f\"int * bool: {10 * True}, type: {type(10 * True)}\")  # bool is implicitly converted to int\n",
    "print(f\"str + str: {'hello' + ' world'}, type: {type('hello' + ' world')}\")\n",
    "\n",
    "# Python doesn't do implicit conversion in many cases\n",
    "try:\n",
    "    result = \"5\" + 10  # This will raise TypeError\n",
    "except TypeError as e:\n",
    "    print(f\"\\nError when mixing incompatible types: {e}\")\n",
    "\n",
    "# Common patterns for safe conversion\n",
    "value = \"5\"\n",
    "number = 10\n",
    "print(f\"\\nSafe conversions:\")\n",
    "print(f\"str + int (safe): {value + str(number)}\")\n",
    "print(f\"str to int + int: {int(value) + number}\")\n",
    "\n",
    "# Converting to numeric values with error handling\n",
    "strings = [\"123\", \"123.45\", \"hello\", \"42x\", \"\"]\n",
    "\n",
    "print(\"\\nSafe numeric conversion with error handling:\")\n",
    "for s in strings:\n",
    "    try:\n",
    "        int_value = int(s)\n",
    "        print(f\"'{s}' converted to int: {int_value}\")\n",
    "    except ValueError:\n",
    "        try:\n",
    "            float_value = float(s)\n",
    "            print(f\"'{s}' converted to float: {float_value}\")\n",
    "        except ValueError:\n",
    "            print(f\"'{s}' cannot be converted to numeric type\")\n",
    "\n",
    "# Using string methods to check before conversion\n",
    "print(\"\\nValidation before conversion:\")\n",
    "for s in strings:\n",
    "    if s.isdigit():\n",
    "        print(f\"'{s}' is a valid integer string\")\n",
    "    elif s.replace(\".\", \"\", 1).isdigit() and s.count(\".\") <= 1:\n",
    "        print(f\"'{s}' is a valid float string\")\n",
    "    else:\n",
    "        print(f\"'{s}' is not a valid numeric string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e75f19",
   "metadata": {},
   "source": [
    "## 7. Type Conversion in NumPy\n",
    "\n",
    "Let's explore various ways to convert between NumPy data types and their implications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c83f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a NumPy array\n",
    "arr_float = np.array([1.1, 2.2, 3.3, 4.4, 5.5])\n",
    "print(f\"Original array: {arr_float}, dtype: {arr_float.dtype}\")\n",
    "\n",
    "# Convert to different types using astype()\n",
    "arr_int = arr_float.astype(np.int32)\n",
    "arr_str = arr_float.astype(np.string_)\n",
    "arr_bool = arr_float.astype(np.bool_)\n",
    "\n",
    "print(\"Conversions:\")\n",
    "print(f\"To int32: {arr_int}, dtype: {arr_int.dtype}\")  # Note: truncates decimal portions\n",
    "print(f\"To string: {arr_str}, dtype: {arr_str.dtype}\")\n",
    "print(f\"To boolean: {arr_bool}, dtype: {arr_bool.dtype}\")  # Non-zero values become True\n",
    "\n",
    "# Converting data types with potential data loss\n",
    "arr_large = np.array([300, 400, 500], dtype=np.int16)  # int16 max is 32767\n",
    "try:\n",
    "    arr_small = arr_large.astype(np.int8)  # int8 max is 127\n",
    "    print(f\"\\nConversion with overflow: {arr_small}\")  # Will wrap around due to overflow\n",
    "except Exception as e:\n",
    "    print(f\"Error during conversion: {e}\")\n",
    "\n",
    "# Converting between signed and unsigned\n",
    "arr_signed = np.array([-5, 0, 5], dtype=np.int8)\n",
    "arr_unsigned = arr_signed.astype(np.uint8)\n",
    "print(f\"\\nSigned array: {arr_signed}, dtype: {arr_signed.dtype}\")\n",
    "print(f\"Unsigned array: {arr_unsigned}, dtype: {arr_unsigned.dtype}\")  # Negative values wrap around\n",
    "\n",
    "# Precision loss in float conversions\n",
    "arr_double = np.array([1.123456789, 2.123456789], dtype=np.float64)\n",
    "arr_single = arr_double.astype(np.float32)\n",
    "arr_back = arr_single.astype(np.float64)  # Going back doesn't restore precision\n",
    "\n",
    "print(f\"\\nDouble precision: {arr_double}, dtype: {arr_double.dtype}\")\n",
    "print(f\"Single precision: {arr_single}, dtype: {arr_single.dtype}\")\n",
    "print(f\"Back to double: {arr_back}, dtype: {arr_back.dtype}\")\n",
    "print(f\"Original vs converted back (equal): {np.array_equal(arr_double, arr_back)}\")\n",
    "\n",
    "# Creating arrays with mixed types\n",
    "mixed_list = [1, 2.5, \"3\", True]\n",
    "arr_mixed = np.array(mixed_list)  # Gets converted to string (object dtype)\n",
    "print(f\"\\nMixed type list to array: {arr_mixed}, dtype: {arr_mixed.dtype}\")\n",
    "\n",
    "# Multiple ways to convert types\n",
    "arr = np.array([1.5, 2.5, 3.5])\n",
    "print(f\"\\nOriginal: {arr}, dtype: {arr.dtype}\")\n",
    "print(f\"Using astype(): {arr.astype(int)}, dtype: {arr.astype(int).dtype}\")\n",
    "print(f\"Using array constructor: {np.array(arr, dtype=int)}, dtype: {np.array(arr, dtype=int).dtype}\")\n",
    "print(f\"Using dtype parameter: {np.int32(arr)}, dtype: {np.int32(arr).dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ab0063",
   "metadata": {},
   "source": [
    "### 7.1 NumPy Type Conversion Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4c0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other NumPy type conversion functions\n",
    "arr = np.array([1.5, 2.6, 3.7, 4.8, 5.9])\n",
    "\n",
    "print(\"NumPy conversion functions:\")\n",
    "print(f\"np.floor(): {np.floor(arr)}, dtype: {np.floor(arr).dtype}\")  # Round down to nearest integer\n",
    "print(f\"np.ceil(): {np.ceil(arr)}, dtype: {np.ceil(arr).dtype}\")  # Round up to nearest integer\n",
    "print(f\"np.round(): {np.round(arr)}, dtype: {np.round(arr).dtype}\")  # Round to nearest integer\n",
    "print(f\"np.trunc(): {np.trunc(arr)}, dtype: {np.trunc(arr).dtype}\")  # Truncate decimal part\n",
    "\n",
    "# Converting from strings to numbers\n",
    "str_arr = np.array(['1.5', '2.5', '3.5'])\n",
    "print(f\"\\nString array: {str_arr}, dtype: {str_arr.dtype}\")\n",
    "print(f\"Converted to float: {str_arr.astype(float)}, dtype: {str_arr.astype(float).dtype}\")\n",
    "\n",
    "# Create a structured array and extract fields with different types\n",
    "structured = np.array([('Alice', 25, 55.0), ('Bob', 30, 85.5)], \n",
    "                      dtype=[('name', 'U10'), ('age', 'i4'), ('weight', 'f4')])\n",
    "print(f\"\\nStructured array:\\n{structured}\")\n",
    "print(f\"Names array: {structured['name']}, dtype: {structured['name'].dtype}\")\n",
    "print(f\"Ages array: {structured['age']}, dtype: {structured['age'].dtype}\")\n",
    "print(f\"Weights array: {structured['weight']}, dtype: {structured['weight'].dtype}\")\n",
    "\n",
    "# View casting - reinterpret bits as a different type without copying\n",
    "uint8_arr = np.array([72, 101, 108, 108, 111], dtype=np.uint8)  # ASCII for \"Hello\"\n",
    "print(f\"\\nUint8 array (ASCII codes): {uint8_arr}\")\n",
    "char_arr = uint8_arr.view('S1')  # View as 1-byte characters\n",
    "print(f\"As characters: {char_arr}\")\n",
    "back_to_uint8 = char_arr.view(np.uint8)  # View back as uint8\n",
    "print(f\"Back to uint8: {back_to_uint8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04954dbb",
   "metadata": {},
   "source": [
    "## 8. Type Conversion in Pandas\n",
    "\n",
    "Let's explore various ways to convert data types in Pandas DataFrames and Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e8d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame with mixed data types\n",
    "data = {\n",
    "    'A': ['1', '2', '3', '4', '5'],                   # strings\n",
    "    'B': [1.1, 2.2, 3.3, 4.4, 5.5],                   # floats\n",
    "    'C': ['True', 'False', 'True', 'False', 'True'],  # string booleans\n",
    "    'D': ['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', '2021-01-05'],  # date strings\n",
    "    'E': ['a', 'b', 'c', 'd', 'e']                    # categories\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame with inferred types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Basic type conversion with astype()\n",
    "df['A_int'] = df['A'].astype(int)\n",
    "df['A_float'] = df['A'].astype(float)\n",
    "df['B_int'] = df['B'].astype(int)\n",
    "df['C_bool'] = df['C'].astype(bool)  # This won't work correctly with 'True'/'False' strings\n",
    "df['E_cat'] = df['E'].astype('category')\n",
    "\n",
    "print(\"\\nAfter basic type conversions:\")\n",
    "print(df.dtypes)\n",
    "print(df)\n",
    "\n",
    "# Convert string boolean values properly\n",
    "df['C_bool_correct'] = df['C'].map({'True': True, 'False': False})\n",
    "\n",
    "# Convert date strings to datetime using to_datetime\n",
    "df['D_datetime'] = pd.to_datetime(df['D'])\n",
    "\n",
    "print(\"\\nAfter advanced type conversions:\")\n",
    "print(df.dtypes)\n",
    "print(df[['C', 'C_bool', 'C_bool_correct', 'D', 'D_datetime']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa0037",
   "metadata": {},
   "source": [
    "### 8.1 Pandas Conversion Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce23c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with diverse data to convert\n",
    "data = {\n",
    "    'int_col': ['1', '2', '3', '4', '5'],\n",
    "    'float_col': ['1.1', '2.2', '3.3', '4.4', '5.5'],\n",
    "    'mixed_numeric': ['1', '2.2', '3', '4.4', '5'],\n",
    "    'bool_col': ['True', 'False', 'YES', 'no', '1'],\n",
    "    'date_col': ['2021-01-01', '01/02/2021', '2021-03-01', '04/01/21', '2021-05-01'],\n",
    "    'categorical': ['small', 'medium', 'large', 'medium', 'small']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df.dtypes)  # All columns are object (string) type\n",
    "print(df)\n",
    "\n",
    "# Using specialized Pandas conversion functions\n",
    "print(\"\\n1. Using pd.to_numeric():\")\n",
    "# Convert to numeric types with error handling\n",
    "for col in ['int_col', 'float_col', 'mixed_numeric']:\n",
    "    # Different error handling options:\n",
    "    # - 'error': default, raises if can't convert\n",
    "    # - 'coerce': convert errors to NaN\n",
    "    # - 'ignore': leave errors as is\n",
    "    df[f\"{col}_num\"] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "print(df[['int_col', 'int_col_num', 'float_col', 'float_col_num', 'mixed_numeric', 'mixed_numeric_num']].head())\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n2. Using pd.to_datetime():\")\n",
    "# Convert to datetime with different formats\n",
    "df['date_std'] = pd.to_datetime(df['date_col'], errors='coerce')  # Auto-detect format\n",
    "df['date_fmt'] = pd.to_datetime(df['date_col'], format='%Y-%m-%d', errors='coerce')  # Specific format\n",
    "\n",
    "print(df[['date_col', 'date_std', 'date_fmt']].head())\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n3. Using pd.to_timedelta():\")\n",
    "# Convert strings to time intervals\n",
    "timedelta_data = ['1 days', '2 hours', '3 minutes', '4 seconds', '5 days 6 hours']\n",
    "df['timedelta_col'] = timedelta_data\n",
    "df['timedelta'] = pd.to_timedelta(df['timedelta_col'])\n",
    "\n",
    "print(df[['timedelta_col', 'timedelta']].head())\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n4. Converting to boolean:\")\n",
    "# Convert various forms of boolean data\n",
    "# True values: 'True', 'true', 't', 'yes', 'y', '1'\n",
    "# False values: 'False', 'false', 'f', 'no', 'n', '0'\n",
    "df['bool_std'] = df['bool_col'].astype('boolean')  # This doesn't handle all cases properly\n",
    "df['bool_custom'] = df['bool_col'].map(lambda x: x.lower() in ['true', 'yes', 'y', '1', 't'])\n",
    "\n",
    "print(df[['bool_col', 'bool_std', 'bool_custom']].head())\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n5. Converting to categorical:\")\n",
    "# Convert to categorical type\n",
    "df['cat'] = df['categorical'].astype('category')\n",
    "# With explicit category order\n",
    "df['cat_ordered'] = pd.Categorical(df['categorical'], \n",
    "                                   categories=['small', 'medium', 'large'], \n",
    "                                   ordered=True)\n",
    "\n",
    "print(df[['categorical', 'cat', 'cat_ordered']].head())\n",
    "print(f\"Categories: {df['cat'].cat.categories}\")\n",
    "print(f\"Ordered categories: {df['cat_ordered'].cat.categories}\")\n",
    "print(f\"Is ordered: {df['cat_ordered'].cat.ordered}\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0b820c",
   "metadata": {},
   "source": [
    "### 8.2 Converting DataFrame Types Efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c917c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a larger DataFrame for demonstrating batch conversions\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "n_rows = 100000\n",
    "\n",
    "large_df = pd.DataFrame({\n",
    "    'id': range(n_rows),\n",
    "    'int_col': np.random.randint(0, 100, size=n_rows),\n",
    "    'float_col': np.random.rand(n_rows),\n",
    "    'small_int': np.random.randint(0, 10, size=n_rows),\n",
    "    'tiny_int': np.random.randint(0, 5, size=n_rows),\n",
    "    'bool_col': np.random.choice([True, False], size=n_rows),\n",
    "    'str_col': np.random.choice(['a', 'b', 'c', 'd', 'e'], size=n_rows),\n",
    "    'date_col': pd.date_range('2021-01-01', periods=n_rows, freq='D')\n",
    "})\n",
    "\n",
    "# Check initial memory usage\n",
    "print(f\"Initial DataFrame memory usage:\")\n",
    "print(large_df.info(memory_usage='deep'))\n",
    "initial_memory = large_df.memory_usage(deep=True).sum()\n",
    "print(f\"Total memory usage: {initial_memory / 1e6:.2f} MB\")\n",
    "\n",
    "# Convert individual columns to more efficient types\n",
    "print(\"\\nOptimizing memory usage...\")\n",
    "\n",
    "# 1. Integer downcasting\n",
    "large_df['int_col_opt'] = pd.to_numeric(large_df['int_col'], downcast='integer')\n",
    "large_df['small_int_opt'] = pd.to_numeric(large_df['small_int'], downcast='integer')\n",
    "large_df['tiny_int_opt'] = pd.to_numeric(large_df['tiny_int'], downcast='integer')\n",
    "\n",
    "# 2. Float downcasting\n",
    "large_df['float_col_opt'] = pd.to_numeric(large_df['float_col'], downcast='float')\n",
    "\n",
    "# 3. Convert strings to categorical\n",
    "large_df['str_col_cat'] = large_df['str_col'].astype('category')\n",
    "\n",
    "# Check memory usage after optimization\n",
    "print(\"\\nDataFrame memory usage after optimization:\")\n",
    "print(large_df.info(memory_usage='deep'))\n",
    "optimized_memory = large_df.memory_usage(deep=True).sum()\n",
    "print(f\"Total memory usage: {optimized_memory / 1e6:.2f} MB\")\n",
    "print(f\"Memory reduction: {(1 - optimized_memory / initial_memory) * 100:.2f}%\")\n",
    "\n",
    "# Memory usage for individual columns\n",
    "print(\"\\nMemory usage comparison for each column type:\")\n",
    "for col in ['int_col', 'int_col_opt', 'small_int', 'small_int_opt', \n",
    "            'tiny_int', 'tiny_int_opt', 'float_col', 'float_col_opt', \n",
    "            'str_col', 'str_col_cat']:\n",
    "    mem_usage = large_df[col].memory_usage(deep=True) / 1e6\n",
    "    print(f\"{col}: {mem_usage:.2f} MB, dtype: {large_df[col].dtype}\")\n",
    "\n",
    "# Batch conversion function\n",
    "def optimize_dtypes(df):\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Optimize integers\n",
    "    int_cols = df.select_dtypes(include=['int64']).columns\n",
    "    for col in int_cols:\n",
    "        result[col] = pd.to_numeric(result[col], downcast='integer')\n",
    "    \n",
    "    # Optimize floats\n",
    "    float_cols = df.select_dtypes(include=['float64']).columns\n",
    "    for col in float_cols:\n",
    "        result[col] = pd.to_numeric(result[col], downcast='float')\n",
    "    \n",
    "    # Convert strings with few unique values to categorical\n",
    "    obj_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in obj_cols:\n",
    "        num_unique_values = len(df[col].unique())\n",
    "        num_total_values = len(df[col])\n",
    "        if num_unique_values / num_total_values < 0.5:  # If less than 50% are unique\n",
    "            result[col] = result[col].astype('category')\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Create a new copy of the original DataFrame to optimize\n",
    "df_original = large_df[['id', 'int_col', 'float_col', 'small_int', 'tiny_int', 'bool_col', 'str_col', 'date_col']]\n",
    "df_optimized = optimize_dtypes(df_original)\n",
    "\n",
    "# Compare memory usage\n",
    "original_mem = df_original.memory_usage(deep=True).sum() / 1e6\n",
    "optimized_mem = df_optimized.memory_usage(deep=True).sum() / 1e6\n",
    "\n",
    "print(f\"\\nBatch optimization results:\")\n",
    "print(f\"Original memory: {original_mem:.2f} MB\")\n",
    "print(f\"Optimized memory: {optimized_mem:.2f} MB\")\n",
    "print(f\"Memory reduction: {(1 - optimized_mem / original_mem) * 100:.2f}%\")\n",
    "print(\"\\nOptimized dtypes:\")\n",
    "print(df_optimized.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d2d5b",
   "metadata": {},
   "source": [
    "## 9. Memory Usage and Efficiency\n",
    "\n",
    "Let's analyze how different data types impact memory usage and computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0c1148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing memory usage across different Python data structures\n",
    "import sys\n",
    "\n",
    "# Memory usage of Python primitive types\n",
    "print(\"Memory usage of Python primitive types:\")\n",
    "print(f\"int (0): {sys.getsizeof(0)} bytes\")\n",
    "print(f\"int (1000): {sys.getsizeof(1000)} bytes\")\n",
    "print(f\"int (10^20): {sys.getsizeof(10**20)} bytes\")  # Python integers have arbitrary precision\n",
    "print(f\"float: {sys.getsizeof(0.0)} bytes\")\n",
    "print(f\"bool: {sys.getsizeof(True)} bytes\")\n",
    "print(f\"str (empty): {sys.getsizeof('')} bytes\")\n",
    "print(f\"str (10 chars): {sys.getsizeof('a' * 10)} bytes\")\n",
    "print(f\"str (100 chars): {sys.getsizeof('a' * 100)} bytes\")\n",
    "\n",
    "# Memory usage of Python containers\n",
    "print(\"\\nMemory usage of empty containers:\")\n",
    "print(f\"list: {sys.getsizeof([])} bytes\")\n",
    "print(f\"tuple: {sys.getsizeof(())} bytes\")\n",
    "print(f\"dict: {sys.getsizeof({})} bytes\")\n",
    "print(f\"set: {sys.getsizeof(set())} bytes\")\n",
    "\n",
    "# Memory usage of containers with elements\n",
    "print(\"\\nMemory usage of containers with elements:\")\n",
    "print(f\"list (10 ints): {sys.getsizeof([0] * 10)} bytes\")\n",
    "print(f\"tuple (10 ints): {sys.getsizeof((0,) * 10)} bytes\")\n",
    "print(f\"dict (10 items): {sys.getsizeof({i: i for i in range(10)})} bytes\")\n",
    "print(f\"set (10 ints): {sys.getsizeof(set(range(10)))} bytes\")\n",
    "\n",
    "# NumPy array memory usage\n",
    "print(\"\\nNumPy array memory usage:\")\n",
    "for dtype in [np.int8, np.int16, np.int32, np.int64, \n",
    "              np.float16, np.float32, np.float64]:\n",
    "    arr = np.zeros(1000, dtype=dtype)\n",
    "    print(f\"1000 zeros as {dtype.__name__}: {arr.nbytes} bytes\")\n",
    "\n",
    "# Pandas Series memory usage\n",
    "print(\"\\nPandas Series memory usage (1000 elements):\")\n",
    "for dtype in ['int8', 'int16', 'int32', 'int64', \n",
    "              'float32', 'float64', 'object', 'category']:\n",
    "    if dtype == 'category':\n",
    "        # For categorical, create data with few unique values\n",
    "        data = pd.Series(['A', 'B', 'C'] * 333 + ['D'])\n",
    "        s = data.astype('category')\n",
    "    elif dtype == 'object':\n",
    "        # For object, use strings\n",
    "        s = pd.Series(['string'] * 1000)\n",
    "    else:\n",
    "        # For numeric types, use zeros\n",
    "        s = pd.Series(np.zeros(1000, dtype=dtype))\n",
    "    \n",
    "    memory = s.memory_usage(deep=True)\n",
    "    print(f\"Series with dtype {s.dtype}: {memory} bytes\")\n",
    "\n",
    "# Visual comparison of memory usage\n",
    "print(\"\\nVisualizing memory usage of different NumPy types:\")\n",
    "dtypes = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "memory_usages = [np.zeros(1000, dtype=dtype).nbytes for dtype in dtypes]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(dtypes, memory_usages)\n",
    "plt.title('Memory Usage of 1000 zeros in NumPy Arrays')\n",
    "plt.xlabel('Data Type')\n",
    "plt.ylabel('Memory Usage (Bytes)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740dcc40",
   "metadata": {},
   "source": [
    "### 9.1 Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac011905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison of different data types\n",
    "import time\n",
    "\n",
    "# Helper function to measure execution time\n",
    "def measure_time(func, *args, **kwargs):\n",
    "    start = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    end = time.time()\n",
    "    return result, end - start\n",
    "\n",
    "# Create arrays of different types\n",
    "size = 10_000_000\n",
    "print(f\"Creating arrays with {size:,} elements...\")\n",
    "\n",
    "# NumPy arrays with different dtypes\n",
    "arrays = {\n",
    "    'float64': np.random.random(size),\n",
    "    'float32': np.random.random(size).astype(np.float32),\n",
    "    'int64': np.random.randint(0, 100, size),\n",
    "    'int32': np.random.randint(0, 100, size).astype(np.int32),\n",
    "    'int16': np.random.randint(0, 100, size).astype(np.int16),\n",
    "    'int8': np.random.randint(0, 100, size).astype(np.int8),\n",
    "}\n",
    "\n",
    "# Performance test for addition\n",
    "print(\"\\nPerformance comparison for array addition:\")\n",
    "for name, arr in arrays.items():\n",
    "    result, duration = measure_time(lambda: arr + arr)\n",
    "    print(f\"{name}: {duration:.6f} seconds\")\n",
    "\n",
    "# Performance test for multiplication\n",
    "print(\"\\nPerformance comparison for array multiplication:\")\n",
    "for name, arr in arrays.items():\n",
    "    result, duration = measure_time(lambda: arr * 2)\n",
    "    print(f\"{name}: {duration:.6f} seconds\")\n",
    "\n",
    "# Performance test for mathematical functions\n",
    "print(\"\\nPerformance comparison for trigonometric operations:\")\n",
    "for name, arr in {k: v for k, v in arrays.items() if 'float' in k}.items():\n",
    "    result, duration = measure_time(lambda: np.sin(arr))\n",
    "    print(f\"sin on {name}: {duration:.6f} seconds\")\n",
    "\n",
    "# Performance test for comparison operations\n",
    "print(\"\\nPerformance comparison for comparison operations:\")\n",
    "for name, arr in arrays.items():\n",
    "    result, duration = measure_time(lambda: arr > arr.mean())\n",
    "    print(f\"{name}: {duration:.6f} seconds\")\n",
    "\n",
    "# Create Pandas DataFrames with different dtypes\n",
    "print(\"\\nCreating DataFrames with different data types...\")\n",
    "df_size = 1_000_000\n",
    "df_float64 = pd.DataFrame({'value': np.random.random(df_size)})\n",
    "df_float32 = pd.DataFrame({'value': np.random.random(df_size).astype(np.float32)})\n",
    "df_int64 = pd.DataFrame({'value': np.random.randint(0, 100, df_size)})\n",
    "df_int32 = pd.DataFrame({'value': np.random.randint(0, 100, df_size).astype(np.int32)})\n",
    "df_category = pd.DataFrame({'value': pd.Categorical(np.random.choice(['A', 'B', 'C', 'D', 'E'], df_size))})\n",
    "df_object = pd.DataFrame({'value': np.random.choice(['A', 'B', 'C', 'D', 'E'], df_size)})\n",
    "\n",
    "# Performance test for filtering in Pandas\n",
    "print(\"\\nPerformance comparison for DataFrame filtering:\")\n",
    "dataframes = {\n",
    "    'float64': df_float64,\n",
    "    'float32': df_float32,\n",
    "    'int64': df_int64,\n",
    "    'int32': df_int32,\n",
    "    'category': df_category,\n",
    "    'object': df_object\n",
    "}\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    if name in ['category', 'object']:\n",
    "        result, duration = measure_time(lambda: df[df['value'] == 'A'])\n",
    "    else:\n",
    "        result, duration = measure_time(lambda: df[df['value'] > 50])\n",
    "    print(f\"{name}: {duration:.6f} seconds\")\n",
    "\n",
    "# Performance test for groupby operations in Pandas\n",
    "print(\"\\nPerformance comparison for DataFrame groupby:\")\n",
    "# Create DataFrames with 1M rows and 10 groups\n",
    "df_size = 1_000_000\n",
    "groups = 10\n",
    "df_int_group = pd.DataFrame({\n",
    "    'group': np.random.randint(0, groups, df_size),\n",
    "    'value': np.random.random(df_size)\n",
    "})\n",
    "df_obj_group = pd.DataFrame({\n",
    "    'group': [f'G{i}' for i in np.random.randint(0, groups, df_size)],\n",
    "    'value': np.random.random(df_size)\n",
    "})\n",
    "df_cat_group = df_obj_group.copy()\n",
    "df_cat_group['group'] = df_cat_group['group'].astype('category')\n",
    "\n",
    "groupby_dfs = {\n",
    "    'int_group': df_int_group,\n",
    "    'obj_group': df_obj_group,\n",
    "    'cat_group': df_cat_group\n",
    "}\n",
    "\n",
    "for name, df in groupby_dfs.items():\n",
    "    result, duration = measure_time(lambda: df.groupby('group')['value'].mean())\n",
    "    print(f\"{name}: {duration:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1657514a",
   "metadata": {},
   "source": [
    "## 10. Handling Data Type Errors\n",
    "\n",
    "Let's explore common data type conversion errors and how to handle them effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a7724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common type conversion errors and handling strategies\n",
    "\n",
    "# 1. Value Error: When the value cannot be converted to the target type\n",
    "print(\"1. Handling ValueError in type conversions:\")\n",
    "strings_to_convert = ['123', '12.3', 'hello', '42x', '']\n",
    "\n",
    "for s in strings_to_convert:\n",
    "    # Simple try-except approach\n",
    "    try:\n",
    "        int_value = int(s)\n",
    "        print(f\"  Successfully converted '{s}' to int: {int_value}\")\n",
    "    except ValueError:\n",
    "        print(f\"  Cannot convert '{s}' to int\")\n",
    "\n",
    "print(\"\\nCascading conversion attempts:\")\n",
    "for s in strings_to_convert:\n",
    "    try:\n",
    "        # Try int first\n",
    "        value = int(s)\n",
    "        print(f\"  '{s}' converted to int: {value}\")\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # If int fails, try float\n",
    "            value = float(s)\n",
    "            print(f\"  '{s}' converted to float: {value}\")\n",
    "        except ValueError:\n",
    "            # If both fail, keep as string\n",
    "            print(f\"  '{s}' kept as string\")\n",
    "\n",
    "# 2. Overflow Error: When the value is too large for the target type\n",
    "print(\"\\n2. Handling overflow in NumPy conversions:\")\n",
    "large_values = np.array([300, 500, 127, 128, 255, 256])\n",
    "print(f\"  Original values: {large_values}\")\n",
    "\n",
    "# With error handling\n",
    "try:\n",
    "    # This will raise an error if warning is converted to error\n",
    "    with np.errstate(over='raise'):\n",
    "        int8_values = large_values.astype(np.int8)\n",
    "    print(f\"  Converted to int8: {int8_values}\")\n",
    "except FloatingPointError:\n",
    "    print(\"  Overflow error occurred during conversion\")\n",
    "\n",
    "# Without error handling (NumPy will wrap around by default)\n",
    "int8_values = large_values.astype(np.int8)\n",
    "print(f\"  Converted to int8 (with wrap-around): {int8_values}\")\n",
    "\n",
    "# Safe conversion with clipping\n",
    "print(\"\\n  Safe conversion with clipping:\")\n",
    "int8_min, int8_max = np.iinfo(np.int8).min, np.iinfo(np.int8).max\n",
    "clipped_values = np.clip(large_values, int8_min, int8_max).astype(np.int8)\n",
    "print(f\"  Clipped to int8 range: {clipped_values}\")\n",
    "\n",
    "# 3. Handling NA values in Pandas\n",
    "print(\"\\n3. Handling NA values in Pandas conversions:\")\n",
    "df = pd.DataFrame({\n",
    "    'A': ['1', '2', None, '4'],\n",
    "    'B': ['1.1', '2.2', 'NaN', '4.4'],\n",
    "    'C': ['2021-01-01', None, 'not-a-date', '2021-01-04']\n",
    "})\n",
    "print(df)\n",
    "\n",
    "print(\"\\nDefault behavior (may raise errors):\")\n",
    "try:\n",
    "    df['A_int'] = df['A'].astype(int)\n",
    "except ValueError as e:\n",
    "    print(f\"  Error: {e}\")\n",
    "\n",
    "print(\"\\nUsing pd.to_numeric with errors='coerce':\")\n",
    "df['A_int'] = pd.to_numeric(df['A'], errors='coerce')\n",
    "df['B_float'] = pd.to_numeric(df['B'], errors='coerce')\n",
    "print(df)\n",
    "\n",
    "print(\"\\nUsing pd.to_datetime with errors='coerce':\")\n",
    "df['C_date'] = pd.to_datetime(df['C'], errors='coerce')\n",
    "print(df)\n",
    "\n",
    "# 4. Custom conversion function with validation\n",
    "print(\"\\n4. Custom conversion function with validation:\")\n",
    "\n",
    "def safe_convert(value, target_type, default=None):\n",
    "    \"\"\"Safely convert a value to target_type, returning default if conversion fails.\"\"\"\n",
    "    try:\n",
    "        if target_type == int:\n",
    "            # For int, try float first to handle '3.0' cases\n",
    "            return int(float(value)) if value is not None and value != '' else default\n",
    "        elif target_type == float:\n",
    "            return float(value) if value is not None and value != '' else default\n",
    "        elif target_type == bool:\n",
    "            if isinstance(value, str):\n",
    "                return value.lower() in ('true', 'yes', 'y', '1', 't') if value else default\n",
    "            return bool(value) if value is not None else default\n",
    "        elif target_type == pd.Timestamp:\n",
    "            return pd.to_datetime(value) if value is not None and value != '' else default\n",
    "        else:\n",
    "            return target_type(value) if value is not None and value != '' else default\n",
    "    except (ValueError, TypeError):\n",
    "        return default\n",
    "\n",
    "# Test the safe_convert function\n",
    "test_values = [\n",
    "    '123', '456.7', 'True', 'yes', 'no', 'false',\n",
    "    '2021-01-01', '01/01/2021', 'not-a-date', None, ''\n",
    "]\n",
    "\n",
    "print(\"Testing safe conversion function:\")\n",
    "for value in test_values:\n",
    "    print(f\"  Value: '{value}'\")\n",
    "    print(f\"    To int: {safe_convert(value, int, default='INVALID')}\")\n",
    "    print(f\"    To float: {safe_convert(value, float, default='INVALID')}\")\n",
    "    print(f\"    To bool: {safe_convert(value, bool, default='INVALID')}\")\n",
    "    print(f\"    To datetime: {safe_convert(value, pd.Timestamp, default='INVALID')}\")\n",
    "\n",
    "# 5. Apply custom conversion to a DataFrame\n",
    "print(\"\\n5. Applying safe conversion to a DataFrame:\")\n",
    "messy_data = {\n",
    "    'id': ['1', '2', '3', '4', '5'],\n",
    "    'value': ['10', '20.5', 'thirty', '40', None],\n",
    "    'ratio': ['0.5', '60%', '0.75', '90%', 'unknown'],\n",
    "    'flag': ['1', 'yes', 'false', 'no', None],\n",
    "    'date': ['2021-01-01', '01/15/2021', '2021-03-01', 'invalid', '']\n",
    "}\n",
    "\n",
    "messy_df = pd.DataFrame(messy_data)\n",
    "print(\"Original messy DataFrame:\")\n",
    "print(messy_df)\n",
    "\n",
    "# Apply safe conversions\n",
    "print(\"\\nAfter safe conversions:\")\n",
    "cleaned_df = messy_df.copy()\n",
    "cleaned_df['id'] = messy_df['id'].apply(lambda x: safe_convert(x, int))\n",
    "cleaned_df['value'] = messy_df['value'].apply(lambda x: safe_convert(x, float))\n",
    "\n",
    "# Custom parsing for percentages\n",
    "def parse_percentage(x):\n",
    "    if isinstance(x, str) and '%' in x:\n",
    "        return float(x.replace('%', '')) / 100\n",
    "    return safe_convert(x, float)\n",
    "\n",
    "cleaned_df['ratio'] = messy_df['ratio'].apply(parse_percentage)\n",
    "cleaned_df['flag'] = messy_df['flag'].apply(lambda x: safe_convert(x, bool))\n",
    "cleaned_df['date'] = pd.to_datetime(messy_df['date'], errors='coerce')\n",
    "\n",
    "print(cleaned_df)\n",
    "print(cleaned_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3404aa29",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've explored a comprehensive overview of data types and conversion techniques in Python, NumPy, and Pandas. Key takeaways include:\n",
    "\n",
    "1. **Python's core data types** provide the foundation for data science operations with flexibility but less efficiency than specialized libraries.\n",
    "\n",
    "2. **NumPy data types** offer memory-efficient storage and faster computation through vectorized operations. Choosing appropriate dtypes can significantly improve performance.\n",
    "\n",
    "3. **Pandas data types** extend Python and NumPy types with specialized capabilities for tabular data, including categoricals, date/time support, and extension arrays.\n",
    "\n",
    "4. **Type conversion** is a common operation that requires careful attention to avoid data loss, precision issues, or errors.\n",
    "\n",
    "5. **Memory usage** varies significantly across different data types, and optimizing types can dramatically reduce memory consumption for large datasets.\n",
    "\n",
    "6. **Error handling** is essential for robust data processing workflows, especially when dealing with real-world data that contains inconsistencies.\n",
    "\n",
    "Understanding data types and conversion techniques is fundamental to efficient and effective data analysis and machine learning workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
