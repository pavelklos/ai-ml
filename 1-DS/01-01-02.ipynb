{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a Data Science Environment\n",
    "\n",
    "This notebook provides a comprehensive guide to setting up and configuring a robust data science environment. We'll cover various tools, package management systems, IDEs, and best practices to create an efficient workflow for data science projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Data Science Environment Requirements\n",
    "\n",
    "A good data science environment should have:\n",
    "\n",
    "- **Python installation**: The core programming language\n",
    "- **Package management**: For installing and managing libraries\n",
    "- **Development environment**: IDEs or notebooks for coding\n",
    "- **Essential libraries**: NumPy, pandas, scikit-learn, matplotlib, etc.\n",
    "- **Environment isolation**: To manage dependencies across projects\n",
    "- **Version control**: To track changes and collaborate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Python Installation Options\n",
    "\n",
    "### Option 1: Anaconda Distribution (Recommended for beginners)\n",
    "\n",
    "Anaconda is a comprehensive distribution that includes Python and many data science packages.\n",
    "\n",
    "**Installation steps:**\n",
    "1. Download Anaconda from [https://www.anaconda.com/products/distribution](https://www.anaconda.com/products/distribution)\n",
    "2. Run the installer and follow the instructions\n",
    "3. Verify installation by opening Anaconda Navigator or running `conda --version` in terminal\n",
    "\n",
    "### Option 2: Miniconda (Lightweight alternative)\n",
    "\n",
    "Miniconda provides a minimal installation with just Python and conda.\n",
    "\n",
    "**Installation steps:**\n",
    "1. Download Miniconda from [https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html)\n",
    "2. Run the installer and follow the instructions\n",
    "3. Verify with `conda --version`\n",
    "\n",
    "### Option 3: Standard Python Installation\n",
    "\n",
    "**Installation steps:**\n",
    "1. Download from [https://www.python.org/downloads/](https://www.python.org/downloads/)\n",
    "2. Install and verify with `python --version`\n",
    "3. Use pip for package management: `pip --version`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Environment Management\n",
    "\n",
    "### Using Conda Environments\n",
    "\n",
    "Conda environments help isolate project dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new conda environment\n",
    "# !conda create -n datasci python=3.9 -y\n",
    "\n",
    "# Activate the environment (for Windows)\n",
    "# !activate datasci\n",
    "\n",
    "# Activate the environment (for Mac/Linux)\n",
    "# !source activate datasci\n",
    "\n",
    "# List available environments\n",
    "# !conda env list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Virtual Environments (venv)\n",
    "\n",
    "If you're using standard Python installation, venv is the built-in solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a virtual environment\n",
    "# !python -m venv datasci_env\n",
    "\n",
    "# Activate the environment (Windows)\n",
    "# !datasci_env\\Scripts\\activate\n",
    "\n",
    "# Activate the environment (Mac/Linux)\n",
    "# !source datasci_env/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Installing Essential Data Science Libraries\n",
    "\n",
    "With your environment activated, install the core libraries for data science work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using conda (recommended if using Anaconda/Miniconda)\n",
    "# !conda install numpy pandas matplotlib scikit-learn scipy jupyter seaborn statsmodels -y\n",
    "\n",
    "# Using pip (works with any Python installation)\n",
    "# !pip install numpy pandas matplotlib scikit-learn scipy jupyter seaborn statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Useful Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization libraries\n",
    "# !pip install plotly bokeh\n",
    "\n",
    "# Machine learning extensions\n",
    "# !pip install xgboost lightgbm catboost\n",
    "\n",
    "# Deep learning\n",
    "# !pip install tensorflow torch\n",
    "\n",
    "# For working with geographic data\n",
    "# !pip install geopandas folium\n",
    "\n",
    "# For natural language processing\n",
    "# !pip install nltk spacy gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Setting Up Development Environments\n",
    "\n",
    "### Jupyter Notebook and JupyterLab\n",
    "\n",
    "Jupyter notebooks are excellent for data exploration and visualization. JupyterLab is a web-based interactive development environment that extends Jupyter notebook functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install JupyterLab if not already installed\n",
    "# !pip install jupyterlab\n",
    "\n",
    "# Run JupyterLab (execute in terminal, not here)\n",
    "# !jupyter lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrated Development Environments (IDEs)\n",
    "\n",
    "For larger projects and production code, consider using a full-featured IDE:\n",
    "\n",
    "1. **VS Code**\n",
    "   - Download from: [https://code.visualstudio.com/](https://code.visualstudio.com/)\n",
    "   - Install Python extension\n",
    "   - Install Jupyter extension\n",
    "\n",
    "2. **PyCharm**\n",
    "   - Download from: [https://www.jetbrains.com/pycharm/](https://www.jetbrains.com/pycharm/)\n",
    "   - Community Edition is free, Professional has more data science features\n",
    "\n",
    "3. **Spyder** (included in Anaconda)\n",
    "   - Scientific Python Development Environment focused on data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Version Control with Git\n",
    "\n",
    "Git helps track changes to your code and collaborate with others.\n",
    "\n",
    "**Installation steps:**\n",
    "1. Download from [https://git-scm.com/downloads](https://git-scm.com/downloads)\n",
    "2. Install and verify with `git --version`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic git setup\n",
    "# !git config --global user.name \"Your Name\"\n",
    "# !git config --global user.email \"your.email@example.com\"\n",
    "\n",
    "# Initialize a new repository\n",
    "# !git init\n",
    "\n",
    "# Create .gitignore for data science projects\n",
    "# !echo \".ipynb_checkpoints\\n*.csv\\n*.xlsx\\n__pycache__/\\ndata/\\nmodels/\" > .gitignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Setting Up a Project Structure\n",
    "\n",
    "Organizing your data science projects properly is crucial for maintainability and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example script to create a data science project structure\n",
    "# !mkdir -p project_name/data/{raw,processed,external}\n",
    "# !mkdir -p project_name/notebooks\n",
    "# !mkdir -p project_name/src/{data,features,models,visualization}\n",
    "# !mkdir -p project_name/models\n",
    "# !mkdir -p project_name/reports/figures\n",
    "# !touch project_name/README.md\n",
    "# !touch project_name/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure looks like this:\n",
    "\n",
    "```\n",
    "project_name/\n",
    "│\n",
    "├── data/               # Data files\n",
    "│   ├── raw/            # Original immutable data\n",
    "│   ├── processed/      # Cleaned and processed data\n",
    "│   └── external/       # Data from third party sources\n",
    "│\n",
    "├── notebooks/          # Jupyter notebooks for exploration\n",
    "│\n",
    "├── src/                # Source code (Python modules)\n",
    "│   ├── data/           # Data processing scripts\n",
    "│   ├── features/       # Feature engineering scripts\n",
    "│   ├── models/         # Model training and prediction scripts\n",
    "│   └── visualization/  # Visualization scripts\n",
    "│\n",
    "├── models/             # Trained models and model predictions\n",
    "│\n",
    "├── reports/            # Reports and presentations\n",
    "│   └── figures/        # Generated graphics and figures\n",
    "│\n",
    "├── README.md           # Project description\n",
    "└── requirements.txt    # Dependencies\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Creating a Requirements File\n",
    "\n",
    "To make your project reproducible, track your dependencies in a requirements file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate requirements.txt from your current environment\n",
    "# !pip freeze > requirements.txt\n",
    "\n",
    "# If using conda\n",
    "# !conda list --export > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Setting Up Environment Variables\n",
    "\n",
    "Environment variables help manage configuration and secrets without hardcoding them in your scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a .env file template (never commit actual secrets to version control)\n",
    "# !echo \"API_KEY=your_api_key_here\\nDATABASE_URL=your_db_connection_string\" > .env.example\n",
    "\n",
    "# Install python-dotenv to work with .env files\n",
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of using environment variables in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for using environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "# load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "# api_key = os.environ.get('API_KEY')\n",
    "# database_url = os.environ.get('DATABASE_URL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Setting Up Jupyter Extensions\n",
    "\n",
    "Jupyter extensions can significantly improve your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Jupyter extensions\n",
    "# !pip install jupyter_contrib_nbextensions\n",
    "# !jupyter contrib nbextension install --user\n",
    "\n",
    "# Enable popular extensions\n",
    "# !jupyter nbextension enable toc2/main\n",
    "# !jupyter nbextension enable collapsible_headings/main\n",
    "# !jupyter nbextension enable code_prettify/code_prettify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Database Connections\n",
    "\n",
    "Many data science projects require connecting to databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install database connection libraries\n",
    "# !pip install sqlalchemy psycopg2-binary pymysql pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of connecting to a SQL database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: SQLite connection\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create a connection to a SQLite database (or use an existing one)\n",
    "# conn = sqlite3.connect('example.db')\n",
    "\n",
    "# Example: create a table and insert data\n",
    "# conn.execute('''\n",
    "#     CREATE TABLE IF NOT EXISTS example_table (\n",
    "#         id INTEGER PRIMARY KEY,\n",
    "#         name TEXT,\n",
    "#         value REAL\n",
    "#     )\n",
    "# ''')\n",
    "# conn.commit()\n",
    "\n",
    "# Use pandas to interact with SQL\n",
    "# df = pd.read_sql(\"SELECT * FROM example_table\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Testing Your Environment\n",
    "\n",
    "Let's run a simple test to make sure your data science environment is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test importing key libraries\n",
    "try:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from sklearn import datasets\n",
    "    \n",
    "    print(\"NumPy version:\", np.__version__)\n",
    "    print(\"Pandas version:\", pd.__version__)\n",
    "    print(\"Matplotlib version:\", plt.matplotlib.__version__)\n",
    "    print(\"Seaborn version:\", sns.__version__)\n",
    "    print(\"Scikit-learn version:\", datasets.__version__)\n",
    "    print(\"\\nAll libraries imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing libraries: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple data science operation test\n",
    "# Load a dataset\n",
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Create a simple plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='sepal length (cm)', y='sepal width (cm)', \n",
    "                hue='target', data=df, palette='viridis')\n",
    "plt.title('Iris Dataset: Sepal Width vs Sepal Length')\n",
    "plt.show()\n",
    "\n",
    "print(\"Your data science environment is working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Environment Sharing and Reproducibility\n",
    "\n",
    "For collaboration, you'll want to share your environment configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a conda environment file\n",
    "# !conda env export > environment.yml\n",
    "\n",
    "# Another person can recreate your environment with:\n",
    "# !conda env create -f environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Next Steps and Best Practices\n",
    "\n",
    "1. **Keep environments minimal**: Only install what you need\n",
    "2. **Document dependencies**: Always maintain requirements.txt or environment.yml\n",
    "3. **Virtual environments**: Create separate environments for different projects\n",
    "4. **Version control**: Track code changes with git\n",
    "5. **Data versioning**: Consider tools like DVC (Data Version Control)\n",
    "6. **Regular updates**: Update packages periodically but be careful of breaking changes\n",
    "7. **Containerization**: Consider Docker for full environment reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Conclusion\n",
    "\n",
    "You've now set up a complete data science environment with:\n",
    "\n",
    "- Python installation\n",
    "- Package and environment management\n",
    "- Essential data science libraries\n",
    "- Development tools and IDEs\n",
    "- Version control\n",
    "- Project organization structure\n",
    "- Database connections\n",
    "- Reproducibility tools\n",
    "\n",
    "This foundation will allow you to efficiently work on data science projects while following best practices for code organization, reproducibility, and collaboration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
