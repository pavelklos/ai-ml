{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89228776",
   "metadata": {},
   "source": [
    "# Basic Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook provides a comprehensive guide to basic exploratory data analysis techniques. EDA is a critical first step in any data analysis project, allowing you to understand the structure, patterns, and peculiarities of your dataset before applying more advanced analytical or machine learning techniques.\n",
    "\n",
    "## What is EDA?\n",
    "\n",
    "Exploratory Data Analysis is an approach to analyzing datasets to summarize their main characteristics, often using visual methods. The primary goal is to:\n",
    "- Understand the data structure\n",
    "- Detect outliers and anomalies\n",
    "- Identify patterns and relationships\n",
    "- Test underlying assumptions\n",
    "- Develop an initial understanding before formal modeling\n",
    "\n",
    "Let's explore the fundamental techniques of EDA!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5678aeaf",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "We'll start by importing the essential Python libraries needed for data analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7bb781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Configure visualization settings\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Display all columns and rows when printing DataFrames\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Suppress warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f00cbd",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "\n",
    "For this demonstration, we'll load a sample dataset. We'll use the Titanic dataset from seaborn, which is a classic dataset for data analysis. We'll also show how to load data from different sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176dddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Load a dataset directly from seaborn\n",
    "titanic_df = sns.load_dataset('titanic')\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Dataset from seaborn:\")\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7aaade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Load from scikit-learn (another common source)\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "\n",
    "print(\"Iris dataset from scikit-learn:\")\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d3901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3: Example of loading from CSV file (commented out since we don't have the file)\n",
    "\"\"\"\n",
    "# For loading from a local CSV file:\n",
    "# data = pd.read_csv('path/to/your/file.csv')\n",
    "\n",
    "# For loading from a URL:\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "data_from_url = pd.read_csv(url)\n",
    "print(\"Dataset from URL:\")\n",
    "data_from_url.head()\n",
    "\"\"\"\n",
    "\n",
    "# For the rest of this notebook, we'll use the Titanic dataset\n",
    "df = titanic_df.copy()\n",
    "print(f\"We'll use the Titanic dataset with {df.shape[0]} rows and {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ddd281",
   "metadata": {},
   "source": [
    "## 3. Data Overview & Structure\n",
    "\n",
    "Next, we'll explore the structure and composition of our dataset using various pandas methods to get a clear understanding of what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b4043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the first few rows of the dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of the dataset information\n",
    "print(\"Dataset information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689a5415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset dimensions\n",
    "print(f\"Dataset shape: {df.shape} (rows, columns)\")\n",
    "\n",
    "# Column names\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c242dadd",
   "metadata": {},
   "source": [
    "## 4. Descriptive Statistics\n",
    "\n",
    "Now that we understand the structure of our data, let's calculate and examine summary statistics to get a better sense of the data's central tendency, dispersion, and distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc805ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive statistics for numerical columns\n",
    "print(\"Descriptive statistics for numerical columns:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cef85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For categorical columns, we can use .describe(include=['object'])\n",
    "print(\"Descriptive statistics for categorical columns:\")\n",
    "df.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc2dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also look at specific statistics for individual columns\n",
    "print(\"Age statistics:\")\n",
    "print(f\"Mean age: {df['age'].mean():.2f} years\")\n",
    "print(f\"Median age: {df['age'].median():.2f} years\")\n",
    "print(f\"Min age: {df['age'].min()} years\")\n",
    "print(f\"Max age: {df['age'].max()} years\")\n",
    "\n",
    "# Mode for categorical variables\n",
    "print(\"\\nMost frequent passenger class:\", df['class'].mode()[0])\n",
    "print(\"Most frequent embarkation point:\", df['embark_town'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59244c5",
   "metadata": {},
   "source": [
    "## 5. Missing Value Analysis\n",
    "\n",
    "Missing data can significantly impact the analysis and subsequent modeling. Let's identify, visualize, and address missing values in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da171c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "missing_values = df.isna().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "# Create a summary DataFrame for missing values\n",
    "missing_data = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Percentage (%)': missing_percentage\n",
    "})\n",
    "\n",
    "# Sort by missing percentage in descending order\n",
    "print(\"Missing data analysis:\")\n",
    "missing_data[missing_data['Missing Values'] > 0].sort_values('Missing Values', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d23c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.isna(), cbar=False, yticklabels=False, cmap='viridis')\n",
    "plt.title('Missing Value Heatmap', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ebea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also visualize the percentage of missing values per column\n",
    "missing_data = missing_data[missing_data['Missing Values'] > 0].sort_values('Percentage (%)', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(missing_data.index, missing_data['Percentage (%)'], color='steelblue')\n",
    "plt.xlabel('Percentage of Missing Values (%)')\n",
    "plt.ylabel('Columns')\n",
    "plt.title('Percentage of Missing Values by Column', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31088a6a",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "\n",
    "There are several ways to handle missing values:\n",
    "1. Remove rows with missing values\n",
    "2. Fill with statistics (mean, median, mode)\n",
    "3. Use advanced imputation techniques\n",
    "\n",
    "Let's demonstrate a few of these methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7068514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataframe to avoid modifying the original\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 1. Fill missing numerical values with median\n",
    "df_clean['age'] = df_clean['age'].fillna(df_clean['age'].median())\n",
    "\n",
    "# 2. Fill missing categorical values with the mode (most frequent)\n",
    "df_clean['embark_town'] = df_clean['embark_town'].fillna(df_clean['embark_town'].mode()[0])\n",
    "df_clean['deck'] = df_clean['deck'].fillna('Unknown')  # for deck, we'll use 'Unknown' instead of mode\n",
    "\n",
    "# 3. Drop the 'embarked' column as it's redundant with 'embark_town'\n",
    "df_clean.drop('embarked', axis=1, inplace=True)\n",
    "\n",
    "# Check if we've handled all missing values\n",
    "print(\"Remaining missing values after handling:\")\n",
    "print(df_clean.isna().sum())\n",
    "\n",
    "# Compare the mean, median, min, max of age before and after imputation\n",
    "print(\"\\nAge statistics before imputation:\")\n",
    "print(df['age'].describe())\n",
    "print(\"\\nAge statistics after imputation:\")\n",
    "print(df_clean['age'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7627dde8",
   "metadata": {},
   "source": [
    "## 6. Distribution of Variables\n",
    "\n",
    "Understanding how variables are distributed helps us identify patterns, outliers, and potential issues with our data. Let's analyze the distributions of key variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d45f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the distribution of passenger ages\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_clean['age'], kde=True, bins=30)\n",
    "plt.title('Age Distribution', fontsize=14)\n",
    "plt.axvline(df_clean['age'].mean(), color='red', linestyle='--', label=f'Mean: {df_clean[\"age\"].mean():.2f}')\n",
    "plt.axvline(df_clean['age'].median(), color='green', linestyle='-.', label=f'Median: {df_clean[\"age\"].median():.2f}')\n",
    "plt.legend()\n",
    "\n",
    "# QQ Plot for normality check\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(df_clean['age'].dropna(), plot=plt)\n",
    "plt.title('QQ Plot of Age', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c41a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the distribution of fare\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Histogram - original scale\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(df_clean['fare'], kde=True, bins=30)\n",
    "plt.title('Fare Distribution', fontsize=14)\n",
    "plt.axvline(df_clean['fare'].mean(), color='red', linestyle='--', label=f'Mean: {df_clean[\"fare\"].mean():.2f}')\n",
    "plt.axvline(df_clean['fare'].median(), color='green', linestyle='-.', label=f'Median: {df_clean[\"fare\"].median():.2f}')\n",
    "plt.legend()\n",
    "\n",
    "# Histogram - log scale\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(np.log1p(df_clean['fare']), kde=True, bins=30)\n",
    "plt.title('Log-transformed Fare Distribution', fontsize=14)\n",
    "\n",
    "# Box plot\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(y=df_clean['fare'])\n",
    "plt.title('Fare Box Plot', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285a9979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of categorical variables\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.countplot(x='class', data=df_clean, palette='viridis')\n",
    "plt.title('Passenger Class Distribution', fontsize=14)\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.countplot(x='sex', data=df_clean, palette='viridis')\n",
    "plt.title('Gender Distribution', fontsize=14)\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.countplot(x='embark_town', data=df_clean, palette='viridis')\n",
    "plt.title('Embarkation Port Distribution', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.countplot(x='survived', data=df_clean, palette='viridis')\n",
    "plt.title('Survival Distribution', fontsize=14)\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc968cd",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis\n",
    "\n",
    "Correlation analysis helps us understand relationships between numerical variables. Let's calculate and visualize correlations in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57259100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns for correlation\n",
    "numeric_df = df_clean.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(\"Correlation matrix:\")\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt='.2f')\n",
    "plt.title('Correlation Matrix of Numerical Variables', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc25f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plots for important correlations\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Fare vs Age\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.scatterplot(x='age', y='fare', hue='survived', data=df_clean, palette='viridis', alpha=0.7)\n",
    "plt.title('Fare vs Age (colored by survival)', fontsize=14)\n",
    "\n",
    "# Fare vs Pclass\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='class', y='fare', data=df_clean, palette='viridis')\n",
    "plt.title('Fare Distribution by Class', fontsize=14)\n",
    "\n",
    "# Age vs Pclass\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x='class', y='age', data=df_clean, palette='viridis')\n",
    "plt.title('Age Distribution by Class', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7094dcb9",
   "metadata": {},
   "source": [
    "## 8. Categorical Variable Analysis\n",
    "\n",
    "Let's explore the categorical variables in more depth to understand their distributions and relationships with other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445d2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of survival by sex\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='sex', hue='survived', data=df_clean, palette='viridis')\n",
    "plt.title('Survival Count by Gender', fontsize=14)\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Add percentages to the plot\n",
    "for i, gender in enumerate(['male', 'female']):\n",
    "    total = len(df_clean[df_clean['sex'] == gender])\n",
    "    survived = len(df_clean[(df_clean['sex'] == gender) & (df_clean['survived'] == 1)])\n",
    "    survival_rate = survived / total * 100\n",
    "    plt.annotate(f'{survival_rate:.1f}%', \n",
    "                xy=(i, survived/2), \n",
    "                ha='center', \n",
    "                va='center',\n",
    "                fontsize=12)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Create a cross-tabulation to calculate survival rates by gender\n",
    "survival_by_sex = pd.crosstab(df_clean['sex'], df_clean['survived'])\n",
    "survival_by_sex_pct = survival_by_sex.div(survival_by_sex.sum(1), axis=0) * 100\n",
    "survival_by_sex_pct.plot(kind='bar', stacked=True, figsize=(8, 6), colormap='viridis')\n",
    "plt.title('Survival Rate by Gender (%)', fontsize=14)\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Percentage')\n",
    "plt.legend(['Did not survive', 'Survived'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371a8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of survival by class\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='class', hue='survived', data=df_clean, palette='viridis')\n",
    "plt.title('Survival Count by Class', fontsize=14)\n",
    "plt.xlabel('Passenger Class')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Create a cross-tabulation to calculate survival rates by class\n",
    "survival_by_class = pd.crosstab(df_clean['class'], df_clean['survived'])\n",
    "survival_by_class_pct = survival_by_class.div(survival_by_class.sum(1), axis=0) * 100\n",
    "survival_by_class_pct.plot(kind='bar', stacked=True, figsize=(8, 6), colormap='viridis')\n",
    "plt.title('Survival Rate by Class (%)', fontsize=14)\n",
    "plt.xlabel('Passenger Class')\n",
    "plt.ylabel('Percentage')\n",
    "plt.legend(['Did not survive', 'Survived'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d310df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a contingency table to analyze the relationship between passenger class and gender\n",
    "contingency_table = pd.crosstab(df_clean['class'], df_clean['sex'])\n",
    "print(\"Class vs Gender Contingency Table:\")\n",
    "print(contingency_table)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "contingency_table.plot(kind='bar', stacked=True, colormap='viridis')\n",
    "plt.title('Distribution of Gender by Passenger Class', fontsize=14)\n",
    "plt.xlabel('Passenger Class')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Gender')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858142ee",
   "metadata": {},
   "source": [
    "## 9. Outlier Detection\n",
    "\n",
    "Outliers can significantly impact statistical analyses and model performance. Let's identify and visualize outliers in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefa517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots are excellent for identifying outliers\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Age Outliers\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(y='age', data=df_clean)\n",
    "plt.title('Age Distribution with Outliers', fontsize=14)\n",
    "\n",
    "# Fare Outliers\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(y='fare', data=df_clean)\n",
    "plt.title('Fare Distribution with Outliers', fontsize=14)\n",
    "\n",
    "# Fare by Class - to see if high fares are outliers or just first class\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.boxplot(x='class', y='fare', data=df_clean)\n",
    "plt.title('Fare Distribution by Class', fontsize=14)\n",
    "\n",
    "# Numerical approach to identifying outliers in fare\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(range(len(df_clean)), df_clean['fare'], alpha=0.5)\n",
    "plt.axhline(y=df_clean['fare'].mean() + 3*df_clean['fare'].std(), color='r', linestyle='--', label='3σ threshold')\n",
    "plt.title('Fare Values with 3σ Threshold', fontsize=14)\n",
    "plt.ylabel('Fare')\n",
    "plt.xlabel('Index')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d59094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying outliers using Z-score and IQR methods\n",
    "\n",
    "def identify_outliers_zscore(df, column, threshold=3):\n",
    "    \"\"\"Identify outliers using Z-score method\"\"\"\n",
    "    z_scores = np.abs(stats.zscore(df[column].dropna()))\n",
    "    outliers = df[column].dropna()[z_scores > threshold]\n",
    "    return outliers\n",
    "\n",
    "def identify_outliers_iqr(df, column):\n",
    "    \"\"\"Identify outliers using IQR method\"\"\"\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)][column]\n",
    "    return outliers\n",
    "\n",
    "# Identify fare outliers\n",
    "fare_outliers_zscore = identify_outliers_zscore(df_clean, 'fare')\n",
    "fare_outliers_iqr = identify_outliers_iqr(df_clean, 'fare')\n",
    "\n",
    "print(f\"Fare outliers using Z-score method: {len(fare_outliers_zscore)}\")\n",
    "print(f\"Fare outliers using IQR method: {len(fare_outliers_iqr)}\")\n",
    "\n",
    "# Identify age outliers\n",
    "age_outliers_zscore = identify_outliers_zscore(df_clean, 'age')\n",
    "age_outliers_iqr = identify_outliers_iqr(df_clean, 'age')\n",
    "\n",
    "print(f\"\\nAge outliers using Z-score method: {len(age_outliers_zscore)}\")\n",
    "print(f\"Age outliers using IQR method: {len(age_outliers_iqr)}\")\n",
    "\n",
    "# Let's look at some of the fare outliers\n",
    "print(\"\\nTop 10 fare outliers (Z-score method):\")\n",
    "fare_outliers_df = df_clean.loc[fare_outliers_zscore.index]\n",
    "fare_outliers_df.sort_values(by='fare', ascending=False)[['class', 'fare', 'sex', 'age']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168e5309",
   "metadata": {},
   "source": [
    "## 10. Basic Data Visualization\n",
    "\n",
    "Finally, let's create some insightful visualizations to gain deeper insights into the dataset relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec0972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pair plot for numerical variables\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(df_clean, \n",
    "             vars=['age', 'fare', 'pclass'],\n",
    "             hue='survived',\n",
    "             diag_kind='kde',\n",
    "             plot_kws={'alpha': 0.6},\n",
    "             palette='viridis')\n",
    "plt.suptitle('Pair Plot of Key Variables', y=1.02, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f836754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plots to compare distributions\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.violinplot(x='class', y='age', hue='survived', data=df_clean, palette='viridis', split=True)\n",
    "plt.title('Age Distribution by Class and Survival', fontsize=14)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.violinplot(x='class', y='fare', hue='survived', data=df_clean, palette='viridis', split=True)\n",
    "plt.title('Fare Distribution by Class and Survival', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of passengers by class, gender, and survival\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Create a FacetGrid\n",
    "g = sns.catplot(\n",
    "    data=df_clean, kind=\"count\",\n",
    "    x=\"class\", hue=\"survived\", col=\"sex\",\n",
    "    palette=\"viridis\", height=6, aspect=.7)\n",
    "\n",
    "# Customize the plot\n",
    "g.set_axis_labels(\"Passenger Class\", \"Count\")\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "g.fig.suptitle('Passenger Counts by Class, Gender, and Survival', fontsize=16, y=1.05)\n",
    "g.add_legend(title=\"Survived\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc788a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a swarm plot to visualize individual data points\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.swarmplot(x='class', y='age', hue='survived', data=df_clean.sample(n=min(300, len(df_clean))), palette='viridis')\n",
    "plt.title('Age by Class and Survival (Sample of Points)', fontsize=14)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.swarmplot(x='embark_town', y='fare', hue='survived', data=df_clean.sample(n=min(300, len(df_clean))), palette='viridis')\n",
    "plt.title('Fare by Embarkation Point and Survival (Sample of Points)', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22181047",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "From our exploratory data analysis of the Titanic dataset, we've gained several key insights:\n",
    "\n",
    "1. **Demographics**: The dataset contains information about 891 passengers with variables including age, sex, class, fare, and survival status.\n",
    "\n",
    "2. **Missing Data**: There were significant missing values in 'age' (~20%) and 'deck' (~77%), which we addressed through imputation.\n",
    "\n",
    "3. **Survival Patterns**:\n",
    "   - Women had a much higher survival rate than men\n",
    "   - Passengers in higher classes (1st class) had better survival rates than those in lower classes\n",
    "   - Age also played a role in survival, with children having better odds\n",
    "\n",
    "4. **Correlations**:\n",
    "   - Fare was strongly correlated with passenger class (higher fares in higher classes)\n",
    "   - Survival was correlated with sex, class, and fare\n",
    "   - Age showed some correlation with class and survival\n",
    "\n",
    "5. **Distributions**:\n",
    "   - Age followed a somewhat normal distribution with a mean around 30 years\n",
    "   - Fare was right-skewed, with most passengers paying lower fares and a few paying much higher amounts\n",
    "   - There were more male passengers than female passengers\n",
    "\n",
    "6. **Outliers**: We identified several outliers, particularly in the fare variable, mostly attributed to first-class passengers.\n",
    "\n",
    "These insights provide a solid foundation for further analysis and modeling, highlighting important relationships and potential predictors of survival."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04812b87",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Based on our EDA, potential next steps could include:\n",
    "\n",
    "1. **Feature Engineering**: Create new features like family size (combining siblings/spouses and parents/children) or fare per person\n",
    "\n",
    "2. **Data Preprocessing**: Normalize numerical features and encode categorical features for modeling\n",
    "\n",
    "3. **Model Building**: Build predictive models to determine factors that influenced survival\n",
    "\n",
    "4. **Advanced Analysis**: Conduct more sophisticated statistical tests to validate the observed patterns\n",
    "\n",
    "5. **Visualization**: Create an interactive dashboard for stakeholders to explore the data and findings\n",
    "\n",
    "EDA is just the beginning of the data science workflow, but it provides critical insights that guide all subsequent analytical decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
